<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Brian D. Williamson" />

<meta name="date" content="2018-10-02" />

<title>Introduction to vimp</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Introduction to vimp</h1>
<h4 class="author"><em>Brian D. Williamson</em></h4>
<h4 class="date"><em>2018-10-02</em></h4>



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p><code>vimp</code> is a package that computes nonparametric estimates of variable importance. Currently, the package supports flexible estimation of an ANOVA-derived measure of variable importance, interpreted as the additional proportion of variability in the outcome explained by including a group of covariates in estimation of the conditional mean. This quantity is a nonparametric generalization of the usual <span class="math inline">\(R^2\)</span> measure.</p>
<p>Variable importance estimates may be computed quickly, depending on the techniques used to estimate the underlying conditional means — if these techniques are slow, then the variable importance procedure will be slow. However, you may save computation time by estimating the conditional means separately, and plugging these estimates into the variable importance procedure.</p>
<p>The code can handle arbitrary dimensions of features, and may be used to estimate the importance of any single feature or group of features for predicting the outcome. The package also includes functions for cross-validated importance and plotting.</p>
<p>The author of the <code>vimp</code> package is Brian Williamson.</p>
</div>
<div id="installation" class="section level2">
<h2>Installation</h2>
<p>Currently, the package may only be downloaded and installed from GitHub using the <code>devtools</code> package. Type the following command in your R console:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># only run if you don't have devtools</span>
<span class="co"># previously installed</span>
<span class="co"># install.packages(&quot;devtools&quot;)</span>
devtools<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;bdwilliamson/vimp&quot;</span>)</code></pre></div>
</div>
<div id="quick-start" class="section level2">
<h2>Quick Start</h2>
<p>This section should serve as a quick guide to using the <code>vimp</code> package — we will cover the main functions using a simulated data example. More details are given in the next section.</p>
<p>First, load the <code>vimp</code> package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;vimp&quot;</span>)</code></pre></div>
<p>Next, create some data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## -------------------------------------------------------------
## problem setup
## -------------------------------------------------------------
## set up the data
n &lt;-<span class="st"> </span><span class="dv">100</span>
p &lt;-<span class="st"> </span><span class="dv">2</span>
s &lt;-<span class="st"> </span><span class="dv">1</span> <span class="co"># desire importance for X_1</span>
x &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">replicate</span>(p, <span class="kw">runif</span>(n, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)))
y &lt;-<span class="st"> </span>(x[,<span class="dv">1</span>])<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(x[,<span class="dv">1</span>]<span class="op">+</span><span class="dv">7</span><span class="op">/</span><span class="dv">5</span>) <span class="op">+</span><span class="st"> </span>(<span class="dv">25</span><span class="op">/</span><span class="dv">9</span>)<span class="op">*</span>(x[,<span class="dv">2</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">1</span>) </code></pre></div>
<p>This creates a matrix of covariates <code>x</code> with two columns, and a vector <code>y</code> of normally-distributed outcome values, for a sample of <code>n = 100</code> study participants.</p>
<p>The workhorse function of <code>vimp</code>, for ANOVA-based variable importance, is <code>vimp_regression</code>. The basic arguments are</p>
<ul>
<li>Y: the outcome (in this example, <code>y</code>)</li>
<li>X: the covariates (in this example, <code>x</code>)</li>
<li>indx: the covariate(s) of interest for evaluating importance (here, either 1 or 2)</li>
<li>run_regression: a logical value telling <code>vimp_regression</code> whether or not to run a regression of Y on X</li>
<li>SL.library: a “library” of learners to pass to the function <code>SuperLearner</code>, if <code>run_regression = TRUE</code></li>
</ul>
<p>This final argument, <code>SL.library</code>, determines the estimators you want to use for the conditional mean of Y given X. Estimates of variable importance rely on good estimators of the conditional mean, so we suggest using flexible estimators and model stacking to do so. One option for this is the <code>SuperLearner</code> package; load that package using</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;SuperLearner&quot;</span>)</code></pre></div>
<pre><code>## Loading required package: nnls</code></pre>
<pre><code>## Super Learner</code></pre>
<pre><code>## Version: 2.0-24</code></pre>
<pre><code>## Package created on 2018-08-10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## load specific algorithms
<span class="kw">library</span>(<span class="st">&quot;gam&quot;</span>)</code></pre></div>
<pre><code>## Loading required package: splines</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loaded gam 1.16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;xgboost&quot;</span>)</code></pre></div>
<p>The code</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">est_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> y, <span class="dt">X =</span> x, <span class="dt">indx =</span> <span class="dv">1</span>, <span class="dt">run_regression =</span> <span class="ot">TRUE</span>, 
<span class="dt">SL.library =</span> <span class="kw">c</span>(<span class="st">&quot;SL.gam&quot;</span>, <span class="st">&quot;SL.xgboost&quot;</span>, <span class="st">&quot;SL.mean&quot;</span>))</code></pre></div>
<p>uses the Super Learner to fit the required regression functions, and computes an estimate of variable importance. We can visualize the estimate, standard error, and confidence interval by printing or typing the object name:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">est_<span class="dv">1</span></code></pre></div>
<pre><code>## Call:
## vimp_regression(Y = y, X = x, indx = 1, run_regression = TRUE, 
##     SL.library = c(&quot;SL.gam&quot;, &quot;SL.xgboost&quot;, &quot;SL.mean&quot;))
## 
## Variable importance estimates:
##       Estimate   SE         95% CI                  
## s = 1 0.08734624 0.03778226 [0.01329437, 0.16139811]</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(est_<span class="dv">1</span>)</code></pre></div>
<pre><code>## Call:
## vimp_regression(Y = y, X = x, indx = 1, run_regression = TRUE, 
##     SL.library = c(&quot;SL.gam&quot;, &quot;SL.xgboost&quot;, &quot;SL.mean&quot;))
## 
## Variable importance estimates:
##       Estimate   SE         95% CI                  
## s = 1 0.08734624 0.03778226 [0.01329437, 0.16139811]</code></pre>
<p>This output shows that we have estimated the importance of <span class="math inline">\(X_2\)</span> to be 0.51, with a 95% confidence interval of [0.37, 0.65].</p>
</div>
<div id="detailed-guide" class="section level2">
<h2>Detailed guide</h2>
<p>Often when working with data we attempt to estimate the conditional mean of the outcome <span class="math inline">\(Y\)</span> given features <span class="math inline">\(X\)</span>, defined as <span class="math inline">\(\mu_P(x) = E_P(Y \mid X = x)\)</span>.</p>
<p>There are many tools for estimating this conditional mean. We might choose a classical parametric tool such as linear regression. We might also want to be model-agnostic and use a more nonparametric approach to estimate the conditional mean. However,</p>
<ul>
<li>This involves using some nonparametric smoothing technique, which requires: (1) choosing a technique, and (2) selecting tuning parameters</li>
<li>Naive optimal tuning balances out the bias and variance of the smoothing estimator. Is this the correct trade-off for estimating the conditional mean?</li>
</ul>
<p>Once we have a good estimate of the conditional mean, it is often of scientific interest to understand which features contribute the most to the variation in <span class="math inline">\(\mu_P\)</span>. Specifically, we might consider <span class="math display">\[\mu_{P, s}(x) = E_P(Y \mid X_{(-s)} = x_{(-s)}),\]</span> where for a vector <span class="math inline">\(v\)</span> and a set of indices <span class="math inline">\(s\)</span>, <span class="math inline">\(v_{-(s)}\)</span> denotes the elements of <span class="math inline">\(v\)</span> with index not in <span class="math inline">\(s\)</span>. By comparing <span class="math inline">\(\mu_{P, s}\)</span> to <span class="math inline">\(\mu_P\)</span> we can evaluate the importance of the <span class="math inline">\(s\)</span>th element (or group of elements).</p>
<p>Assume that our data are generated according to the mechanism <span class="math inline">\(P_0\)</span>. We can then define a nonparametric measure of variable importance, <span class="math display">\[\psi_{0, s} = \frac{\int [\mu_{P_0}(x) - \mu_{P_0, s}(x)]^2dP_0(x)}{\text{Var}_{P_0}(Y)},\]</span> which is the proportion of the variability in the outcome explained by including <span class="math inline">\(X_j\)</span> in our chosen estimation technique.</p>
<p>This document introduces you to the basic tools in vimp and how to apply them to a dataset. I will explore the two different ways of obtaining variable estimates using vimp:</p>
<ol style="list-style-type: decimal">
<li>You only specify a <em>library</em> of candidate estimators for the conditional means <span class="math inline">\(\mu_{P_0}\)</span> and <span class="math inline">\(\mu_{P_0, s}\)</span>; you allow vimp to obtain the optimal estimates of these quantities using the <code>SuperLearner</code> <span class="citation">(van der Laan, Polley, and Hubbard 2007)</span>, and use these estimates to obtain variable importance estimates</li>
<li>You have a favorite estimator for the conditional means; you simply want vimp to obtain variable importance estimates using this estimator</li>
</ol>
<div id="a-look-at-the-boston-housing-study-data" class="section level3">
<h3>A look at the Boston housing study data</h3>
<p>Throughout this document I will use the Boston housing study data <span class="citation">(Harrison and Rubinfeld 1978)</span>, freely available from the <code>MASS</code> package. Use <code>?Boston</code> to see documentation for these data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## load the library, view the data
<span class="kw">library</span>(<span class="st">&quot;MASS&quot;</span>)
<span class="kw">data</span>(Boston)
<span class="kw">head</span>(Boston)</code></pre></div>
<pre><code>##      crim zn indus chas   nox    rm  age    dis rad tax ptratio  black
## 1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90
## 2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90
## 3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83
## 4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63
## 5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90
## 6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12
##   lstat medv
## 1  4.98 24.0
## 2  9.14 21.6
## 3  4.03 34.7
## 4  2.94 33.4
## 5  5.33 36.2
## 6  5.21 28.7</code></pre>
<p>In addition to the median house value <code>medv</code>, the outcome of interest, there are measurements on four groups of variables. First are accessibility features: the weighted distances to five employment centers in the Boston region <code>dis</code>, where housing prices are expected to increase with decreased distance to employment centers; and an index of accessibility to radial highways <code>rad</code>, where housing prices are expected to increase with increased access to highways. Second are neighborhood features: the proportion of black residents in the population <code>black</code>; the proportion of population that is lower status <code>lstat</code>, which denotes adults without some high school education and male workers classified as laborers; the crime rate <code>crim</code>; the proportion of a town’s residential land zoned for lots greater than 25,000 square feet <code>zn</code>; the proportion of nonretail business acres per town <code>indus</code>; the full value property tax rate <code>tax</code>; the pupil-teacher ratio by school district <code>ptratio</code>; and an indicator of whether the tract of land borders the Charles River <code>chas</code>. The third group are structural features: the average number of rooms in owner units <code>rm</code>; and the proportion of owner units built prior to 1940 <code>age</code>. The final group is the nitrogen oxide concentration <code>nox</code>.</p>
<p>Since there are 13 features and four groups, it is of interest to determine variable importance both for the 13 features separately and for the four groups of features.</p>
</div>
<div id="a-first-approach-linear-regression" class="section level3">
<h3>A first approach: linear regression</h3>
<p>Suppose that I believe that a linear model truly holds in the Boston housing data. In that case, I would be justified in only fitting a linear regression to estimate the conditional means; this means that in my importance analysis, I should also use only linear regression. This is achieved by the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## estimate the full conditional mean using linear regression
full.mod &lt;-<span class="st"> </span><span class="kw">lm</span>(medv <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> Boston)
full.fit &lt;-<span class="st"> </span><span class="kw">predict</span>(full.mod)

## estimate the reduced conditional means for each of the individual variables
X &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(Boston[, <span class="op">-</span><span class="dv">14</span>]) <span class="co"># remove the outcome for the predictor matrix</span>

red.mod.crim &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[,<span class="op">-</span><span class="dv">1</span>])
red.fit.crim &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.crim)

red.mod.zn &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[,<span class="op">-</span><span class="dv">2</span>])
red.fit.zn &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.zn)

red.mod.indus &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[,<span class="op">-</span><span class="dv">3</span>])
red.fit.indus &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.indus)

red.mod.chas &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[,<span class="op">-</span><span class="dv">4</span>])
red.fit.chas &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.chas)

red.mod.nox &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[,<span class="op">-</span><span class="dv">5</span>])
red.fit.nox &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.nox)

red.mod.rm &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[, <span class="op">-</span><span class="dv">6</span>])
red.fit.rm &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.rm)

red.mod.age &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[,<span class="op">-</span><span class="dv">7</span>])
red.fit.age &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.age)

red.mod.dis &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[, <span class="op">-</span><span class="dv">8</span>])
red.fit.dis &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.dis)

red.mod.rad &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[,<span class="op">-</span><span class="dv">9</span>])
red.fit.rad &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.rad)

red.mod.tax &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[,<span class="op">-</span><span class="dv">10</span>])
red.fit.tax &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.tax)

red.mod.ptratio &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[,<span class="op">-</span><span class="dv">11</span>])
red.fit.ptratio &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.ptratio)

red.mod.black &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[,<span class="op">-</span><span class="dv">12</span>])
red.fit.black &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.black)

red.mod.lstat &lt;-<span class="st"> </span><span class="kw">lm</span>(full.fit <span class="op">~</span><span class="st"> </span>X[,<span class="op">-</span><span class="dv">13</span>])
red.fit.lstat &lt;-<span class="st"> </span><span class="kw">predict</span>(red.mod.lstat)

## load the library
<span class="kw">library</span>(<span class="st">&quot;vimp&quot;</span>)

## plug these into vim
lm.vim.crim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.crim, <span class="dt">indx =</span> <span class="dv">1</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.zn &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.zn, <span class="dt">indx =</span> <span class="dv">2</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.indus &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.indus, <span class="dt">indx =</span> <span class="dv">3</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.chas &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.chas, <span class="dt">indx =</span> <span class="dv">4</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.nox &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.nox, <span class="dt">indx =</span> <span class="dv">5</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.rm &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.rm, <span class="dt">indx =</span> <span class="dv">6</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.age &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.age, <span class="dt">indx =</span> <span class="dv">7</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.dis &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.dis, <span class="dt">indx =</span> <span class="dv">8</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.rad &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.rad, <span class="dt">indx =</span> <span class="dv">9</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.tax &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.tax, <span class="dt">indx =</span> <span class="dv">10</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.ptratio &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.ptratio, <span class="dt">indx =</span> <span class="dv">11</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.black &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.black, <span class="dt">indx =</span> <span class="dv">12</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)
lm.vim.lstat &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit.lstat, <span class="dt">indx =</span> <span class="dv">13</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

## make a table with the estimates using the merge_vim() function
lm.mat &lt;-<span class="st"> </span><span class="kw">merge_vim</span>(lm.vim.crim, lm.vim.zn, lm.vim.indus, lm.vim.chas,
                lm.vim.nox, lm.vim.rm, lm.vim.age, lm.vim.dis, lm.vim.rad,
                lm.vim.tax, lm.vim.ptratio, lm.vim.black, lm.vim.lstat)
## print out the matrix
lm.mat<span class="op">$</span>mat</code></pre></div>
<pre><code>##                         est           se           cil          ciu
## lm.vim.lstat   5.643838e-02 2.279363e-02  0.0117636818 0.1011130864
## lm.vim.rm      4.380820e-02 1.694131e-02  0.0106038484 0.0770125548
## lm.vim.dis     2.885111e-02 7.474835e-03  0.0142007022 0.0435015157
## lm.vim.ptratio 2.795733e-02 6.834094e-03  0.0145627519 0.0413519065
## lm.vim.nox     1.140445e-02 4.755140e-03  0.0020845435 0.0207243480
## lm.vim.rad     1.121712e-02 4.348758e-03  0.0026937144 0.0197405309
## lm.vim.black   6.335620e-03 3.702814e-03 -0.0009217619 0.0135930026
## lm.vim.zn      6.027980e-03 3.608834e-03 -0.0010452051 0.0131011654
## lm.vim.crim    5.693839e-03 4.275991e-03 -0.0026869488 0.0140746263
## lm.vim.tax     5.671312e-03 2.484119e-03  0.0008025278 0.0105400962
## lm.vim.chas    5.126155e-03 4.834211e-03 -0.0043487238 0.0146010341
## lm.vim.indus   5.891587e-05 2.840487e-04 -0.0004978094 0.0006156412
## lm.vim.age     1.447559e-06 6.784973e-05 -0.0001315355 0.0001344306</code></pre>
</div>
<div id="building-a-library-of-learners" class="section level3">
<h3>Building a library of learners</h3>
<p>In general, we don’t believe that a linear model truly holds. Thinking about potential model misspecification leads us to consider other algorithms. Suppose that I prefer to use generalized additive models <span class="citation">(Hastie and Tibshirani 1990)</span> to estimate <span class="math inline">\(\mu_{P_0}\)</span> and <span class="math inline">\(\mu_{P_0, s}\)</span>, so I am planning on using the <code>gam</code> package. Suppose that you prefer to use the elastic net <span class="citation">(Zou and Hastie 2005)</span>, and are planning to use the <code>glmnet</code> package.</p>
<p>The choice of either method is somewhat subjective, and I also will have to use a technique like cross-validation to determine an optimal tuning parameter in each case. It is also possible that neither additive models nor the elastic net will do a good job estimating the true conditional means!</p>
<p>This motivates using <code>SuperLearner</code> to allow the data to determine the optimal combination of <em>base learners</em> from a <em>library</em> that I define. These base learners are a combination of different methods (e.g., generalized additive models and elastic net) and instances of the same method with different tuning parameter values (e.g., additive models with 3 and 4 degrees of freedom). The Super Learner is an example of model stacking, or model aggregation — these approaches use a data-adaptive combination of base learners to make predictions.</p>
<p>For instance, my library could include additive models, elastic net , random forests <span class="citation">(Breiman 2001)</span>, and gradient boosted trees <span class="citation">(Friedman 2001)</span> as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## load the library
<span class="kw">library</span>(SuperLearner)

## create a function for boosted stumps
SL.gbm.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="cf">function</span>(..., <span class="dt">interaction.depth =</span> <span class="dv">1</span>) <span class="kw">SL.gbm</span>(..., <span class="dt">interaction.depth =</span> interaction.depth)

## create GAMs with different degrees of freedom
SL.gam.<span class="dv">3</span> &lt;-<span class="st"> </span><span class="cf">function</span>(..., <span class="dt">deg.gam =</span> <span class="dv">3</span>) <span class="kw">SL.gam</span>(..., <span class="dt">deg.gam =</span> deg.gam)
SL.gam.<span class="dv">4</span> &lt;-<span class="st"> </span><span class="cf">function</span>(..., <span class="dt">deg.gam =</span> <span class="dv">4</span>) <span class="kw">SL.gam</span>(..., <span class="dt">deg.gam =</span> deg.gam)
SL.gam.<span class="dv">5</span> &lt;-<span class="st"> </span><span class="cf">function</span>(..., <span class="dt">deg.gam =</span> <span class="dv">5</span>) <span class="kw">SL.gam</span>(..., <span class="dt">deg.gam =</span> deg.gam)

## add more levels of alpha for glmnet
create.SL.glmnet &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">alpha =</span> <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>)) {
  <span class="cf">for</span> (mm <span class="cf">in</span> <span class="kw">seq</span>(<span class="kw">length</span>(alpha))) {
    <span class="kw">eval</span>(<span class="kw">parse</span>(<span class="dt">file =</span> <span class="st">&quot;&quot;</span>, <span class="dt">text =</span> <span class="kw">paste</span>(<span class="st">'SL.glmnet.'</span>, alpha[mm], <span class="st">'&lt;- function(..., alpha = '</span>, alpha[mm], <span class="st">') SL.glmnet(..., alpha = alpha)'</span>, <span class="dt">sep =</span> <span class="st">''</span>)), <span class="dt">envir =</span> .GlobalEnv)
  }
  <span class="kw">invisible</span>(<span class="ot">TRUE</span>)
}
<span class="kw">create.SL.glmnet</span>()

## add tuning parameters for randomForest
create.SL.randomForest &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">tune =</span> <span class="kw">list</span>(<span class="dt">mtry =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">7</span>), <span class="dt">nodesize =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>))) {
  tuneGrid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(tune, <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)
  <span class="cf">for</span> (mm <span class="cf">in</span> <span class="kw">seq</span>(<span class="kw">nrow</span>(tuneGrid))) {
    <span class="kw">eval</span>(<span class="kw">parse</span>(<span class="dt">file =</span> <span class="st">&quot;&quot;</span>, <span class="dt">text =</span> <span class="kw">paste</span>(<span class="st">&quot;SL.randomForest.&quot;</span>, mm, <span class="st">&quot;&lt;- function(..., mtry = &quot;</span>, tuneGrid[mm, <span class="dv">1</span>], <span class="st">&quot;, nodesize = &quot;</span>, tuneGrid[mm, <span class="dv">2</span>], <span class="st">&quot;) SL.randomForest(..., mtry = mtry, nodesize = nodesize)&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)), <span class="dt">envir =</span> .GlobalEnv)
  }
  <span class="kw">invisible</span>(<span class="ot">TRUE</span>)
}
<span class="kw">create.SL.randomForest</span>()

## create the library
learners &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;SL.gam&quot;</span>, <span class="st">&quot;SL.gam.3&quot;</span>, <span class="st">&quot;SL.gam.4&quot;</span>, <span class="st">&quot;SL.gam.5&quot;</span>,
              <span class="st">&quot;SL.glmnet&quot;</span>, <span class="st">&quot;SL.glmnet.0.25&quot;</span>, <span class="st">&quot;SL.glmnet.0.5&quot;</span>, <span class="st">&quot;SL.glmnet.0.75&quot;</span>,
              <span class="st">&quot;SL.randomForest&quot;</span>, <span class="st">&quot;SL.randomForest.1&quot;</span>, <span class="st">&quot;SL.randomForest.2&quot;</span>, <span class="st">&quot;SL.randomForest.3&quot;</span>,
              <span class="st">&quot;SL.randomForest.4&quot;</span>, <span class="st">&quot;SL.randomForest.5&quot;</span>, <span class="st">&quot;SL.randomForest.6&quot;</span>, <span class="st">&quot;SL.randomForest.7&quot;</span>,
              <span class="st">&quot;SL.randomForest.8&quot;</span>, <span class="st">&quot;SL.randomForest.9&quot;</span>,
              <span class="st">&quot;SL.gbm.1&quot;</span>)</code></pre></div>
<p>Now that I have created the library of learners, I can move on to estimating variable importance.</p>
</div>
<div id="estimating-variable-importance-for-a-single-variable" class="section level3">
<h3>Estimating variable importance for a single variable</h3>
<p>The main function for ANOVA-derived variable importance in the <code>vimp</code> package is the <code>vimp_regression()</code> function. There are five main arguments to <code>vimp_regression()</code>:</p>
<ul>
<li><code>Y</code>, the outcome</li>
<li><code>f1</code> and <code>f2</code>, the fitted values from a sequential regression procedure; or <code>X</code>, the covariates</li>
<li><code>indx</code>, which determines the feature I want to estimate variable importance for</li>
<li><code>run_regression</code>, which determines whether or not the sequential regression procedure is run on <code>Y</code> and <code>X</code></li>
</ul>
<p>There are two ways to compute importance:</p>
<ol style="list-style-type: decimal">
<li>Supply outcome <code>Y</code>, covariates <code>X</code>, and a library of learners (e.g., <code>learners</code> above) with <code>run_regression = TRUE</code></li>
<li>Supply outcome <code>Y</code> and fitted values for estimates of <span class="math inline">\(\mu_{P_0}\)</span> and <span class="math inline">\(\mu_{P_0, s}\)</span> with <code>run_regression = FALSE</code></li>
</ol>
<p>I will illustrate each of these choices in order below, but in practice I use (3), since it allows the most flexibility, and all time-intensive computation occurs before calling <code>vimp_regression()</code>; however, this involves more work on your end.</p>
<p>Suppose that the first feature that I want to estimate variable importance for is nitrogen oxide, <code>nox</code>. Since this is the first feature, say I choose (1) above. Then supplying <code>vimp_regression()</code> with</p>
<ul>
<li><code>Y = Boston$medv</code></li>
<li><code>X = X</code></li>
<li><code>indx = 5</code></li>
<li><code>run_regression = TRUE</code></li>
</ul>
<p>means that:</p>
<ul>
<li>I want to use <code>SuperLearner()</code> to estimate the conditional means <span class="math inline">\(\mu_{P_0}\)</span> and <span class="math inline">\(\mu_{P_0,s}\)</span></li>
<li>I want to estimate variable importance for the fifth column of the <code>Boston</code> covariates, which is <code>nox</code></li>
</ul>
<p>The call to <code>vimp_regression()</code> looks like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## load the library
<span class="kw">library</span>(<span class="st">&quot;vimp&quot;</span>)

## first re-order the data so that the outcome is in the first column
Boston2 &lt;-<span class="st"> </span>Boston[, <span class="dv">1</span><span class="op">:</span><span class="dv">13</span>]

## now estimate variable importance
<span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">X =</span> Boston2[, <span class="op">-</span><span class="dv">1</span>, <span class="dt">drop =</span> <span class="ot">FALSE</span>], 
    <span class="dt">indx =</span> <span class="dv">5</span>, <span class="dt">run_regression =</span> <span class="ot">TRUE</span>, <span class="dt">SL.library =</span> learners)</code></pre></div>
<p>While this is the preferred method for estimating variable importance, using a large library of learners may cause the function to take time to run. Usually this is okay — in general, you took a long time to collect the data, so letting an algorithm run for a few hours should not be an issue.</p>
<p>However, for the sake of illustration, I can estimate varibable importance for nitrogen oxide only using only two base learners as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## load the library
<span class="kw">library</span>(<span class="st">&quot;vimp&quot;</span>)

## first re-order the data so that the outcome is in the first column
Boston2 &lt;-<span class="st"> </span>Boston[, <span class="dv">1</span><span class="op">:</span><span class="dv">13</span>]

## new learners library, with only one learner for illustration only
learners.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;SL.gam&quot;</span>, <span class="st">&quot;SL.glmnet&quot;</span>)

## now estimate variable importance
nox.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">X =</span> Boston2[, <span class="op">-</span><span class="dv">1</span>, <span class="dt">drop =</span> <span class="ot">FALSE</span>], 
    <span class="dt">indx =</span> <span class="dv">5</span>, <span class="dt">run_regression =</span> <span class="ot">TRUE</span>, <span class="dt">SL.library =</span> learners.<span class="dv">2</span>)</code></pre></div>
<p>This code takes approximately 11 seconds to run on a (not very fast) PC. Under the hood, <code>vimp_regression()</code> fits the <code>SuperLearner()</code> function with the specified library, and then returns fitted values and variable importance estimates. This is most suitable for estimating variable importance for the first feature on a given dataset. I can display these estimates:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nox.vim</code></pre></div>
<pre><code>## Call:
## vimp_regression(Y = Boston$medv, X = Boston2[, -1, drop = FALSE], 
##     indx = 5, run_regression = TRUE, SL.library = learners.2)
## 
## Variable importance estimates:
##       Estimate   SE         95% CI                  
## s = 5 0.06811769 0.01594961 [0.03685703, 0.09937835]</code></pre>
<p>The object returned by <code>vimp_regression()</code> also contains fitted values from using <code>SuperLearner()</code>; I access these using <code>$full_fit</code> and <code>$red_fit</code>. For example,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(nox.vim<span class="op">$</span>full_fit)</code></pre></div>
<pre><code>##       [,1]
## 1 28.97021
## 2 23.65169
## 3 31.98207
## 4 31.82171
## 5 30.35997
## 6 26.97160</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(nox.vim<span class="op">$</span>red_fit)</code></pre></div>
<pre><code>##       [,1]
## 1 31.67029
## 2 24.73148
## 3 30.12662
## 4 30.67474
## 5 27.95888
## 6 28.21884</code></pre>
<p>I said earlier that I want to obtain estimates of all individual features in these data, so let’s choose average number of rooms (<code>rm</code>) next. Now that I have estimated variable importance for nitrogen oxide, the <code>full.fit</code> object contains our estimate of <span class="math inline">\(\mu_{P_0}\)</span>. Since I have spent the time to estimate this using <code>SuperLearner()</code>, there is no reason to estimate this function again. This leads me to choose (2) above, since I have already estimated variable importance on one feature in this dataset. Using the small learners library (again only for illustration) yields</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## specify that full.fit doesn't change
full.fit &lt;-<span class="st"> </span>nox.vim<span class="op">$</span>full_fit

## estimate variable importance for the average number of rooms
reduced_fit &lt;-<span class="st"> </span>SuperLearner<span class="op">::</span><span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> Boston2[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span>), <span class="dt">drop =</span> <span class="ot">FALSE</span>], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>)
red.fit &lt;-<span class="st"> </span><span class="kw">predict</span>(reduced_fit)<span class="op">$</span>pred
rm.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> red.fit, <span class="dt">indx =</span> <span class="dv">6</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

rm.vim</code></pre></div>
<pre><code>## Call:
## vimp_regression(Y = Boston$medv, f1 = full.fit, f2 = red.fit, 
##     indx = 6, run_regression = FALSE)
## 
## Variable importance estimates:
##       Estimate   SE         95% CI                  
## s = 6 0.06811769 0.01594961 [0.03685703, 0.09937835]</code></pre>
<p>This takes approximately 5 seconds — now rather than estimating both conditional means, I am only estimating one.</p>
<p>If I choose (2), then I have to use a single method from the library, or call <code>SuperLearner()</code> myself, prior to estimating variable importance. Then <code>vimp_regression()</code> returns variable importance estimates based on these fitted values. For example, let’s estimate variable importance for the distance to radial highways using this approach.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## set up the data
x &lt;-<span class="st"> </span>Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">8</span>, <span class="dv">14</span>)] <span class="co"># this removes dis and medv</span>

## fit a GAM and glmnet using SuperLearner
reduced.mod &lt;-<span class="st"> </span><span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> x, <span class="dt">SL.library =</span> learners.<span class="dv">2</span>)
reduced.fit &lt;-<span class="st"> </span><span class="kw">predict</span>(reduced.mod)<span class="op">$</span>pred
## this takes 2 seconds

## estimate variable importance
dis.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced.fit, <span class="dt">indx =</span> <span class="dv">8</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>I can obtain estimates for the remaining individual features in the same way (again using only two base learners for illustration):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reduced_crim &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
crim.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_crim,
                <span class="dt">indx =</span> <span class="dv">1</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

reduced_zn &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
zn.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_zn,
                <span class="dt">indx =</span> <span class="dv">2</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

reduced_indus &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
indus.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_indus,
                <span class="dt">indx =</span> <span class="dv">3</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

reduced_chas &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
chas.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_chas,
                <span class="dt">indx =</span> <span class="dv">4</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

reduced_age &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
age.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_age,
                <span class="dt">indx =</span> <span class="dv">7</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

reduced_rad &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
rad.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_rad,
                <span class="dt">indx =</span> <span class="dv">9</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

reduced_tax &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
tax.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_tax,
                <span class="dt">indx =</span> <span class="dv">10</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

reduced_ptratio &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">11</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
ptratio.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_ptratio,
                <span class="dt">indx =</span> <span class="dv">11</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

reduced_black &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">12</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
black.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_black,
                <span class="dt">indx =</span> <span class="dv">12</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

reduced_lstat &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> full.fit, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">13</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
lstat.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_lstat,
                <span class="dt">indx =</span> <span class="dv">13</span>, <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>Now that I have estimates of each of individual feature’s variable importance, I can view them all simultaneously by plotting:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## combine the objects together
ests &lt;-<span class="st"> </span><span class="kw">merge_vim</span>(crim.vim, zn.vim, indus.vim, chas.vim,
                nox.vim, rm.vim, age.vim, dis.vim, rad.vim,
                tax.vim, ptratio.vim, black.vim, lstat.vim)

## create a vector of names; must be in the same order as the
## mat object in ests
nms &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Prop. lower status&quot;</span>, <span class="st">&quot;Avg. num. rooms&quot;</span>, <span class="st">&quot;Pupil-teacher ratio&quot;</span>, <span class="st">&quot;Nitrogen oxide&quot;</span>, <span class="st">&quot;Distance&quot;</span>, <span class="st">&quot;Crime&quot;</span>, <span class="st">&quot;Access to radial hwys&quot;</span>, <span class="st">&quot;Property tax rate&quot;</span>, <span class="st">&quot;Charles riv.&quot;</span>, <span class="st">&quot;Prop. black&quot;</span>, <span class="st">&quot;Prop. business&quot;</span>, <span class="st">&quot;Prop. large zoned&quot;</span>, <span class="st">&quot;Age&quot;</span>)

## plot
<span class="kw">plot</span>(ests, nms, <span class="dt">pch =</span> <span class="dv">16</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Estimate&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Estimated variable importance for individual features&quot;</span>, <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>))</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
</div>
</div>
<div id="estimating-variable-importance-for-a-group-of-variables" class="section level2">
<h2>Estimating variable importance for a group of variables</h2>
<p>Now that I have estimated variable importance for each of the individual features, I can estimate variable importance for each of the groups that I mentioned above: accessibility features, structural features, nitrogen oxide, and neighborhood features.</p>
<p>The only difference between estimating variable importance for a group of features rather than an individual feature is that now I specify a vector for <code>s</code>; I can use any of the options listed in the previous section to compute these estimates.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## get the estimates
reduced_struct &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
structure.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_struct, <span class="dt">indx =</span> <span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">7</span>), <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

reduced_access &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
access.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_access, <span class="dt">indx =</span> <span class="kw">c</span>(<span class="dv">8</span>, <span class="dv">9</span>), <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

reduced_neigh &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">SuperLearner</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">X =</span> Boston[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">14</span>)], <span class="dt">SL.library =</span> learners.<span class="dv">2</span>))<span class="op">$</span>pred
neigh.vim &lt;-<span class="st"> </span><span class="kw">vimp_regression</span>(<span class="dt">Y =</span> Boston<span class="op">$</span>medv, <span class="dt">f1 =</span> full.fit, <span class="dt">f2 =</span> reduced_access,
                <span class="dt">indx =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">13</span>), <span class="dt">run_regression =</span> <span class="ot">FALSE</span>)

## combine and plot
groups &lt;-<span class="st"> </span><span class="kw">merge_vim</span>(structure.vim, access.vim, neigh.vim, nox.vim)
nms.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Neighborhood&quot;</span>, <span class="st">&quot;Structure&quot;</span>, <span class="st">&quot;Accessibility&quot;</span>, <span class="st">&quot;Nitrogen oxide&quot;</span>)
<span class="kw">plot</span>(groups, nms.<span class="dv">2</span>, <span class="dt">pch =</span> <span class="dv">16</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Estimate&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Estimated variable importance for groups&quot;</span>, <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>))</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-breiman2001">
<p>Breiman, L. 2001. “Random Forests” 45. Machine Learning.</p>
</div>
<div id="ref-friedman2001">
<p>Friedman, JH. 2001. “Greedy Function Approximation: A Gradient Boosting Machine.” The Annals of Applied Statistics.</p>
</div>
<div id="ref-harrison1978">
<p>Harrison, D, and DL Rubinfeld. 1978. “Hedonic Housing Prices and the Demand for Clean Air” 5. Journal of Environmental Economics and Management.</p>
</div>
<div id="ref-hastie1990">
<p>Hastie, TJ, and RJ Tibshirani. 1990. <em>Generalized Additive Models</em>. Vol. 43. CRC Press.</p>
</div>
<div id="ref-vanderlaan2007">
<p>van der Laan, MJ, EC Polley, and AE Hubbard. 2007. “Super Learner” 6. Statistical Applications in Genetics and Molecular Biology.</p>
</div>
<div id="ref-zou2005">
<p>Zou, H, and TJ Hastie. 2005. “Regularization and Variable Selection via the Elastic Net.” Journal of the Royal Statistical Society: Series B (Statistical Methodology).</p>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
