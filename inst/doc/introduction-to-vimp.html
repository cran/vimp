<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Brian D. Williamson" />

<meta name="date" content="2022-11-10" />

<title>Introduction to vimp</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Introduction to <code>vimp</code></h1>
<h4 class="author">Brian D. Williamson</h4>
<h4 class="date">2022-11-10</h4>



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p><code>vimp</code> is a package that computes nonparametric estimates
of variable importance and provides valid inference on the true
importance. The package supports flexible estimation of variable
importance based on the difference in nonparametric <span class="math inline">\(R^2\)</span>, classification accuracy, and area
under the receiver operating characteristic curve (AUC). These
quantities are all nonparametric generalizations of the usual measures
in simple parametric models (e.g., linear models). For more details, see
the accompanying manuscripts <span class="citation">Williamson, Gilbert,
Carone, et al. (2020)</span>, <span class="citation">Williamson,
Gilbert, Simon, et al. (2021)</span>, and <span class="citation">Williamson and Feng (2020)</span>.</p>
<p>Variable importance estimates may be computed quickly, depending on
the techniques used to estimate the underlying conditional means — if
these techniques are slow, then the variable importance procedure will
be slow.</p>
<p>The code can handle arbitrary dimensions of features, and may be used
to estimate the importance of any single feature or group of features
for predicting the outcome. The package also includes functions for
cross-validated importance.</p>
<p>The author and maintainer of the <code>vimp</code> package is <a href="https://bdwilliamson.github.io/">Brian Williamson</a>. The methods
implemented here have also been implemented in Python under the package
<a href="https://github.com/bdwilliamson/vimpy"><code>vimpy</code></a>.</p>
</div>
<div id="installation" class="section level2">
<h2>Installation</h2>
<p>A stable version of the package may be downloaded and installed from
CRAN. Type the following command in your R console to install the stable
version of <code>vimp</code>:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;vimp&quot;</span>)</span></code></pre></div>
<p>A development version of the package may be downloaded and installed
from GitHub using the <code>devtools</code> package. Type the following
command in your R console to install the development version of
<code>vimp</code>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># only run if you don&#39;t have devtools</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># previously installed</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;devtools&quot;)</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">&quot;bdwilliamson/vimp&quot;</span>)</span></code></pre></div>
</div>
<div id="quick-start" class="section level2">
<h2>Quick Start</h2>
<p>This section should serve as a quick guide to using the
<code>vimp</code> package — we will cover the main functions for
estimating <span class="math inline">\(R^2\)</span>-based variable
importance using a simulated data example. More details are given in the
next section.</p>
<p>First, load the <code>vimp</code> package:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;vimp&quot;</span>)</span></code></pre></div>
<p>Next, create some data:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># problem setup</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------------------------------</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># set up the data</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5678910</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="co"># desire importance for X_1</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">replicate</span>(p, <span class="fu">runif</span>(n, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)))</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> (x[,<span class="dv">1</span>])<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>(x[,<span class="dv">1</span>]<span class="sc">+</span><span class="dv">7</span><span class="sc">/</span><span class="dv">5</span>) <span class="sc">+</span> (<span class="dv">25</span><span class="sc">/</span><span class="dv">9</span>)<span class="sc">*</span>(x[,<span class="dv">2</span>])<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># set up folds for hypothesis testing</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>folds <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">rep</span>(<span class="fu">seq_len</span>(<span class="dv">2</span>), <span class="at">length =</span> <span class="fu">length</span>(y)))</span></code></pre></div>
<p>This creates a matrix of covariates <code>x</code> with two columns,
a vector <code>y</code> of normally-distributed outcome values, and a
set of folds for a sample of <code>n = 100</code> study
participants.</p>
<p>The workhorse function of <code>vimp</code>, for <span class="math inline">\(R^2\)</span>-based variable importance, is
<code>vimp_rsquared</code>. There are two ways to compute variable
importance: in the first method, you allow <code>vimp</code> to run
regressions for you and return variable importance; in the second method
(discussed in <a href="precomputed-regressions.html">“Using precomputed
regression function estimates in <code>vimp</code>”</a>), you run the
regressions yourself and plug these into <code>vimp</code>. I will focus
on the first method here. The basic arguments are</p>
<ul>
<li>Y: the outcome (in this example, <code>y</code>)</li>
<li>X: the covariates (in this example, <code>x</code>)</li>
<li>indx: the covariate(s) of interest for evaluating importance (here,
either 1 or 2)</li>
<li>run_regression: a logical value telling <code>vimp_rsquared</code>
whether or not to run a regression of Y on X (<code>TRUE</code> in this
example)</li>
<li>SL.library: a “library” of learners to pass to the function
<code>SuperLearner</code> (since
<code>run_regression = TRUE</code>)</li>
<li>V: the number of folds to use for cross-fitted variable
importance</li>
</ul>
<p>This second-to-last argument, <code>SL.library</code>, determines the
estimators you want to use for the conditional mean of Y given X.
Estimates of variable importance rely on good estimators of the
conditional mean, so we suggest using flexible estimators and model
stacking to do so. One option for this is the <code>SuperLearner</code>
package; load that package using</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;SuperLearner&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: package &#39;SuperLearner&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;nnls&#39; was built under R version 4.0.3</code></pre>
<pre><code>## Warning: package &#39;gam&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;foreach&#39; was built under R version 4.0.5</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load specific algorithms</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;ranger&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: package &#39;ranger&#39; was built under R version 4.0.5</code></pre>
<p>The code</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>est_1 <span class="ot">&lt;-</span> <span class="fu">vimp_rsquared</span>(<span class="at">Y =</span> y, <span class="at">X =</span> x, <span class="at">indx =</span> <span class="dv">1</span>, <span class="at">run_regression =</span> <span class="cn">TRUE</span>,</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">SL.library =</span> <span class="fu">c</span>(<span class="st">&quot;SL.ranger&quot;</span>, <span class="st">&quot;SL.mean&quot;</span>), <span class="at">V =</span> <span class="dv">2</span>,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">env =</span> <span class="fu">environment</span>())</span></code></pre></div>
<p>uses the Super Learner to fit the required regression functions, and
computes an estimate of variable importance for the importance of <span class="math inline">\(X_1\)</span>. We can visualize the estimate,
standard error, and confidence interval by printing or typing the object
name:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>est_1</span></code></pre></div>
<pre><code>## Variable importance estimates:
##       Estimate   SE         95% CI         VIMP &gt; 0 p-value   
## s = 1 0.06225463 0.04636901 [0, 0.1531362] FALSE    0.08970218</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(est_1)</span></code></pre></div>
<pre><code>## Variable importance estimates:
##       Estimate   SE         95% CI         VIMP &gt; 0 p-value   
## s = 1 0.06225463 0.04636901 [0, 0.1531362] FALSE    0.08970218</code></pre>
<p>This output shows that we have estimated the importance of <span class="math inline">\(X_1\)</span> to be 0.062, with a 95% confidence
interval of [0, 0.153].</p>
</div>
<div id="detailed-guide" class="section level2">
<h2>Detailed guide</h2>
<p>In this section, we provide a fuller example of estimating <span class="math inline">\(R^2\)</span>-based variable importance in the
context of assessing the importance of amino acid sequence features in
predicting the neutralization sensitivity of the HIV virus to the
broadly neutralizing antibody VRC01. For more information about this
study, see <span class="citation">Magaret, Benkeser, Williamson, et al.
(2019)</span>.</p>
<p>Often when working with data we attempt to estimate the conditional
mean of the outcome <span class="math inline">\(Y\)</span> given
features <span class="math inline">\(X\)</span>, defined as <span class="math inline">\(\mu_P(x) = E_P(Y \mid X = x)\)</span>.</p>
<p>There are many tools for estimating this conditional mean. We might
choose a classical parametric tool such as linear regression. We might
also want to be model-agnostic and use a more nonparametric approach to
estimate the conditional mean. However,</p>
<ul>
<li>This involves using some nonparametric smoothing technique, which
requires: (1) choosing a technique, and (2) selecting tuning
parameters</li>
<li>Naive optimal tuning balances out the bias and variance of the
smoothing estimator. Is this the correct trade-off for estimating the
conditional mean?</li>
</ul>
<p>Once we have a good estimate of the conditional mean, it is often of
scientific interest to understand which features contribute the most to
the variation in <span class="math inline">\(\mu_P\)</span>.
Specifically, we might consider <span class="math display">\[\mu_{P,
s}(x) = E_P(Y \mid X_{(-s)} = x_{(-s)}),\]</span> where for a vector
<span class="math inline">\(v\)</span> and a set of indices <span class="math inline">\(s\)</span>, <span class="math inline">\(v_{-(s)}\)</span> denotes the elements of <span class="math inline">\(v\)</span> with index not in <span class="math inline">\(s\)</span>. By comparing <span class="math inline">\(\mu_{P, s}\)</span> to <span class="math inline">\(\mu_P\)</span> we can evaluate the importance of
the <span class="math inline">\(s\)</span>th element (or group of
elements).</p>
<p>Assume that our data are generated according to the mechanism <span class="math inline">\(P_0\)</span>. We define the population <span class="math inline">\(R^2\)</span> value of a given regression function
<span class="math inline">\(\mu\)</span> as <span class="math inline">\(R^2(\mu, P_0) = 1 - \frac{E_{P_0}\{Y -
\mu(X)\}^2}{var_{P_0}(Y)}\)</span>, where the numerator of this
expression is the population mean squared error and the denominator is
the population variance. We can then define a nonparametric measure of
variable importance, <span class="math display">\[\psi_{0, s} =
R^2(\mu_{P_0}, P_0) - R^2(\mu_{P_0,s}, P_0),\]</span> which is the
proportion of the variability in the outcome explained by including
<span class="math inline">\(X_j\)</span> in our chosen estimation
technique.</p>
<p>This document introduces you to the basic tools in <code>vimp</code>
and how to apply them to a dataset. I will explore one method for
obtaining variable estimates using <code>vimp</code>: you only specify a
<em>library</em> of candidate estimators for the conditional means <span class="math inline">\(\mu_{P_0}\)</span> and <span class="math inline">\(\mu_{P_0, s}\)</span>; you allow <code>vimp</code>
to obtain the optimal estimates of these quantities using the
<code>SuperLearner</code> <span class="citation">(Laan, Polley, and
Hubbard 2007)</span>, and use these estimates to obtain variable
importance estimates. A second method (using precomputed estimates of
the regression functions) exists and is described in <a href="precomputed-regressions.html">“Using precomputed regression
function estimates in <code>vimp</code>”</a>.</p>
<div id="a-look-at-the-vrc01-data" class="section level3">
<h3>A look at the VRC01 data</h3>
<p>Throughout this document I will use the VRC01 data <span class="citation">(Magaret, Benkeser, Williamson, et al. 2019)</span>, a
subset of the data freely available from the Los Alamos National
Laboratory’s Compile, Neutralize, and Tally Neutralizing Antibody Panels
database. Information about these data is available <a href="https://doi.org/10.1371/journal.pcbi.1006952">here</a>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># read in the data</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;vrc01&quot;</span>)</span></code></pre></div>
<p>While there are several outcomes of interest in these data
(continuous measures of neutralization and binary measures of
resistance), we will focus on the binary measure of resistance to VRC01
given by <code>ic50.censored</code>. This variable is a binary indicator
that the concentration of VRC01 necessary to neutralize 50% of viral
replicates in a sample (IC-50) was right-censored; since higher values
of IC-50 imply a more resistant virus, this indicator is a proxy for
viral resistance. In addition to the outcome of interest, there are
measurements on several groups of variables: viral subtype, geographic
region of origin (a potential confounding variable), amino acid sequence
features (further grouped into the CD4 binding sites, VRC01 binding
footprint, sites with sufficient exposed surface area, sites identified
as important for glycosylation, sites with residues that covary with the
VRC01 binding footprint, sites associated with VRC01-specific potential
N-linked glycosylation (PNGS) effects, sites in gp41 associated with
VRC01 neutralization or sensitivity, sites for indicating N-linked
glycosylation), region-specific counts of PNGS, viral geometry, cysteine
counts, and steric bulk at critical locations.</p>
<p>For the sake of simplicity, we will focus here on only three groups
of features: viral subtype, geographic region of origin, and viral
geometry features.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;dplyr&quot;</span>)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;tidyselect&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: package &#39;tidyselect&#39; was built under R version 4.0.5</code></pre>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># retain only the columns of interest for this analysis</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> vrc01<span class="sc">$</span>ic50.censored</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> vrc01 <span class="sc">%&gt;%</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">starts_with</span>(<span class="st">&quot;geog&quot;</span>), <span class="fu">starts_with</span>(<span class="st">&quot;subtype&quot;</span>), <span class="fu">starts_with</span>(<span class="st">&quot;length&quot;</span>))</span></code></pre></div>
<p>Since there are 17 features and two groups, it is of interest to
determine variable importance both for the individual features
separately and for the two groups of features (since the geographic
variables are potential confounders).</p>
</div>
<div id="a-first-approach-linear-regression" class="section level3">
<h3>A first approach: linear regression</h3>
<p>Suppose that I believe that a linear model truly describes the
relationship between the outcome and the covariates in these data. In
that case, I would be justified in only fitting a linear regression to
estimate the conditional means; this means that in my importance
analysis, I should also use only linear regression. The analysis is
achieved by the following:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>geog_indx <span class="ot">&lt;-</span> <span class="fu">max</span>(<span class="fu">which</span>(<span class="fu">grepl</span>(<span class="st">&quot;geog&quot;</span>, <span class="fu">names</span>(X))))</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(<span class="fu">ncol</span>(X) <span class="sc">-</span> geog_indx)) {</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># note that we&#39;re using a small number of cross-fitting folds for speed</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  lm_vim <span class="ot">&lt;-</span> <span class="fu">vim</span>(<span class="at">Y =</span> y, <span class="at">X =</span> X, <span class="at">indx =</span> geog_indx <span class="sc">+</span> i, <span class="at">run_regression =</span> <span class="cn">TRUE</span>, <span class="at">SL.library =</span> <span class="st">&quot;SL.lm&quot;</span>, <span class="at">type =</span> <span class="st">&quot;r_squared&quot;</span>, <span class="at">cvControl =</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="dv">2</span>))</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (i <span class="sc">==</span> <span class="dv">1</span>) {</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    lm_mat <span class="ot">&lt;-</span> lm_vim</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    lm_mat <span class="ot">&lt;-</span> <span class="fu">merge_vim</span>(lm_mat, lm_vim)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co"># print out the importance</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>lm_mat</span></code></pre></div>
<pre><code>## Variable importance estimates:
##        Estimate   SE         95% CI                  VIMP &gt; 0 p-value   
## s = 5  0.13438499 0.06330276 [0.01031386, 0.2584561]  TRUE    0.01688141
## s = 11 0.09569336 0.06240703 [0.00000000, 0.2180089] FALSE    0.06259177
## s = 18 0.07087508 0.05996798 [0.00000000, 0.1884102] FALSE    0.11862626
## s = 13 0.06857330 0.06312482 [0.00000000, 0.1922957] FALSE    0.13867032
## s = 8  0.05317778 0.06370201 [0.00000000, 0.1780314] FALSE    0.20191808
## s = 12 0.03756380 0.06238020 [0.00000000, 0.1598267] FALSE    0.27352878
## s = 21 0.02864616 0.06110488 [0.00000000, 0.1484095] FALSE    0.31960515
## s = 20 0.01252676 0.06701578 [0.00000000, 0.1438753] FALSE    0.42586066
## s = 16 0.01146941 0.06511882 [0.00000000, 0.1391000] FALSE    0.43009570
## s = 6  0.01018668 0.06250895 [0.00000000, 0.1327020] FALSE    0.43527356
## s = 7  0.00000000 0.06565987 [0.00000000, 0.1286910] FALSE    0.56052497
## s = 9  0.00000000 0.06131146 [0.00000000, 0.1201682] FALSE    0.85483413
## s = 10 0.00000000 0.06182744 [0.00000000, 0.1211796] FALSE    0.74269077
## s = 14 0.00000000 0.06162074 [0.00000000, 0.1207744] FALSE    0.63428683
## s = 15 0.00000000 0.06549287 [0.00000000, 0.1283637] FALSE    0.62766542
## s = 17 0.00000000 0.06045251 [0.00000000, 0.1184847] FALSE    0.86887592
## s = 19 0.00000000 0.06174183 [0.00000000, 0.1210118] FALSE    0.78557864</code></pre>
</div>
<div id="building-a-library-of-learners" class="section level3">
<h3>Building a library of learners</h3>
<p>In general, we don’t believe that a linear model truly holds.
Thinking about potential model misspecification leads us to consider
other algorithms. Suppose that I prefer to use generalized additive
models <span class="citation">(Hastie and Tibshirani 1990)</span> to
estimate <span class="math inline">\(\mu_{P_0}\)</span> and <span class="math inline">\(\mu_{P_0, s}\)</span>, so I am planning on using
the <code>gam</code> package. Suppose that you prefer to use the elastic
net <span class="citation">(Zou and Hastie 2005)</span>, and are
planning to use the <code>glmnet</code> package.</p>
<p>The choice of either method is somewhat subjective, and I also will
have to use a technique like cross-validation to determine an optimal
tuning parameter in each case. It is also possible that neither additive
models nor the elastic net will do a good job estimating the true
conditional means!</p>
<p>This motivates using <code>SuperLearner</code> to allow the data to
determine the optimal combination of <em>base learners</em> from a
<em>library</em> that I define. These base learners are a combination of
different methods (e.g., generalized additive models and elastic net)
and instances of the same method with different tuning parameter values
(e.g., additive models with 3 and 4 degrees of freedom). The Super
Learner is an example of model stacking, or model aggregation — these
approaches use a data-adaptive combination of base learners to make
predictions.</p>
<p>For instance, my library could include the elastic net, random
forests <span class="citation">(Breiman 2001)</span>, and gradient
boosted trees <span class="citation">(Friedman 2001)</span> as
follows:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a function for boosted stumps</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>SL.gbm<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="cf">function</span>(..., <span class="at">interaction.depth =</span> <span class="dv">1</span>) <span class="fu">SL.gbm</span>(..., <span class="at">interaction.depth =</span> interaction.depth)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># create GAMs with different degrees of freedom</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>SL.gam<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="cf">function</span>(..., <span class="at">deg.gam =</span> <span class="dv">3</span>) <span class="fu">SL.gam</span>(..., <span class="at">deg.gam =</span> deg.gam)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>SL.gam<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="cf">function</span>(..., <span class="at">deg.gam =</span> <span class="dv">4</span>) <span class="fu">SL.gam</span>(..., <span class="at">deg.gam =</span> deg.gam)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>SL.gam<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="cf">function</span>(..., <span class="at">deg.gam =</span> <span class="dv">5</span>) <span class="fu">SL.gam</span>(..., <span class="at">deg.gam =</span> deg.gam)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co"># add more levels of alpha for glmnet</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>create.SL.glmnet <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">alpha =</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>)) {</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (mm <span class="cf">in</span> <span class="fu">seq</span>(<span class="fu">length</span>(alpha))) {</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">eval</span>(<span class="fu">parse</span>(<span class="at">file =</span> <span class="st">&quot;&quot;</span>, <span class="at">text =</span> <span class="fu">paste</span>(<span class="st">&#39;SL.glmnet.&#39;</span>, alpha[mm], <span class="st">&#39;&lt;- function(..., alpha = &#39;</span>, alpha[mm], <span class="st">&#39;) SL.glmnet(..., alpha = alpha)&#39;</span>, <span class="at">sep =</span> <span class="st">&#39;&#39;</span>)), <span class="at">envir =</span> .GlobalEnv)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">invisible</span>(<span class="cn">TRUE</span>)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="fu">create.SL.glmnet</span>()</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="co"># add tuning parameters for randomForest</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>create.SL.randomForest <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">tune =</span> <span class="fu">list</span>(<span class="at">mtry =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">7</span>), <span class="at">nodesize =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>))) {</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>  tuneGrid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(tune, <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (mm <span class="cf">in</span> <span class="fu">seq</span>(<span class="fu">nrow</span>(tuneGrid))) {</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">eval</span>(<span class="fu">parse</span>(<span class="at">file =</span> <span class="st">&quot;&quot;</span>, <span class="at">text =</span> <span class="fu">paste</span>(<span class="st">&quot;SL.randomForest.&quot;</span>, mm, <span class="st">&quot;&lt;- function(..., mtry = &quot;</span>, tuneGrid[mm, <span class="dv">1</span>], <span class="st">&quot;, nodesize = &quot;</span>, tuneGrid[mm, <span class="dv">2</span>], <span class="st">&quot;) SL.randomForest(..., mtry = mtry, nodesize = nodesize)&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;&quot;</span>)), <span class="at">envir =</span> .GlobalEnv)</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">invisible</span>(<span class="cn">TRUE</span>)</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a><span class="fu">create.SL.randomForest</span>()</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a><span class="co"># create the library</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;SL.glmnet&quot;</span>, <span class="st">&quot;SL.glmnet.0.25&quot;</span>, <span class="st">&quot;SL.glmnet.0.5&quot;</span>, <span class="st">&quot;SL.glmnet.0.75&quot;</span>,</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;SL.randomForest&quot;</span>, <span class="st">&quot;SL.randomForest.1&quot;</span>, <span class="st">&quot;SL.randomForest.2&quot;</span>, <span class="st">&quot;SL.randomForest.3&quot;</span>,</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;SL.randomForest.4&quot;</span>, <span class="st">&quot;SL.randomForest.5&quot;</span>, <span class="st">&quot;SL.randomForest.6&quot;</span>, <span class="st">&quot;SL.randomForest.7&quot;</span>,</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;SL.randomForest.8&quot;</span>, <span class="st">&quot;SL.randomForest.9&quot;</span>,</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;SL.gbm.1&quot;</span>)</span></code></pre></div>
<p>Now that I have created the library of learners, I can move on to
estimating variable importance.</p>
</div>
<div id="estimating-variable-importance-for-a-single-variable" class="section level3">
<h3>Estimating variable importance for a single variable</h3>
<p>The main function for R-squared-based variable importance in the
<code>vimp</code> package is the <code>vimp_rsquared()</code> function.
There are five main arguments to <code>vimp_rsquared()</code>:</p>
<ul>
<li><code>Y</code>, the outcome</li>
<li><code>X</code>, the covariates</li>
<li><code>indx</code>, which determines the feature I want to estimate
variable importance for</li>
<li><code>SL.library</code>, the library of candidate learners</li>
<li><code>V</code>, the number of cross-fitting folds (also referred to
as cross-validation folds) to use for computing variable importance</li>
</ul>
<p>The main arguments differ if precomputed regression function
estimates are used; please see <a href="precomputed-regressions.html">“Using precomputed regression
function estimates in <code>vimp</code>”</a> for further discussion of
this case.</p>
<p>Suppose that the first feature that I want to estimate variable
importance for is whether the viral subtype is 01_AE,
<code>subtype.is.01_AE</code>. Then supplying
<code>vimp_rsquared()</code> with</p>
<ul>
<li><code>Y = y</code></li>
<li><code>X = X</code></li>
<li><code>indx = 5</code></li>
<li><code>SL.library = learners</code></li>
<li><code>V = 5</code></li>
</ul>
<p>means that:</p>
<ul>
<li>I want to use <code>SuperLearner()</code> to estimate the
conditional means <span class="math inline">\(\mu_{P_0}\)</span> and
<span class="math inline">\(\mu_{P_0,s}\)</span>, and my candidate
library is <code>learners</code></li>
<li>I want to estimate variable importance for the fifth column of the
VRC01 covariates, which is <code>subtype.is.01_AE</code></li>
<li>I want to use five-fold cross-fitting to estimate importance</li>
</ul>
<p>The call to <code>vimp_rsquared()</code> looks like this:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vimp_rsquared</span>(<span class="at">Y =</span> y, <span class="at">X =</span> X,</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">indx =</span> <span class="dv">5</span>, <span class="at">run_regression =</span> <span class="cn">TRUE</span>, <span class="at">SL.library =</span> learners, <span class="at">V =</span> <span class="dv">5</span>)</span></code></pre></div>
<p>While this is the preferred method for estimating variable
importance, using a large library of learners may cause the function to
take time to run. Usually this is okay — in general, you took a long
time to collect the data, so letting an algorithm run for a few hours
should not be an issue.</p>
<p>However, for the sake of illustration, I can estimate varibable
importance for 01_AE subtype only using only using a small library, a
small number of cross-validation folds in the Super Learner, and a small
number of cross-fitting folds as follows (again, I suggest using a
larger number of folds and a larger library in practice):</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># small learners library</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>learners<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;SL.ranger&quot;</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co"># small number of cross-fitting folds</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>V <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co"># small number of CV folds for Super Learner</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>sl_cvcontrol <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="dv">2</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># now estimate variable importance</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5678</span>)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>start_time <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>subtype_01_AE_vim <span class="ot">&lt;-</span> <span class="fu">vimp_rsquared</span>(<span class="at">Y =</span> y, <span class="at">X =</span> X, <span class="at">indx =</span> <span class="dv">5</span>, <span class="at">SL.library =</span> learners<span class="fl">.2</span>, <span class="at">na.rm =</span> <span class="cn">TRUE</span>, <span class="at">env =</span> <span class="fu">environment</span>(), <span class="at">V =</span> V, <span class="at">cvControl =</span> sl_cvcontrol, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>end_time <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span></code></pre></div>
<p>This code takes approximately 0.44 seconds to run on a (not very
fast) PC. I can display these estimates:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>subtype_01_AE_vim</span></code></pre></div>
<pre><code>## Variable importance estimates:
##       Estimate   SE         95% CI         VIMP &gt; 0 p-value   
## s = 5 0.09419998 0.05592714 [0, 0.2038152] TRUE     0.04605858</code></pre>
<p>The object returned by <code>vimp_rsquared()</code> also contains
lists of fitted values from using <code>SuperLearner()</code>; I access
these using <code>$full_fit</code> and <code>$red_fit</code>. For
example,</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(subtype_01_AE_vim<span class="sc">$</span>full_fit[[<span class="dv">1</span>]])</span></code></pre></div>
<pre><code>## [1] 0.06375393</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(subtype_01_AE_vim<span class="sc">$</span>red_fit[[<span class="dv">1</span>]])</span></code></pre></div>
<pre><code>## [1] 0.05942255</code></pre>
<p>I can obtain estimates for the remaining individual features in the
same way (again using only using a small library for illustration):</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>ests <span class="ot">&lt;-</span> subtype_01_AE_vim</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(<span class="fu">ncol</span>(X) <span class="sc">-</span> geog_indx <span class="sc">-</span> <span class="dv">1</span>)) {</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># note that we&#39;re using a small number of cross-fitting folds for speed</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>  this_vim <span class="ot">&lt;-</span> <span class="fu">vimp_rsquared</span>(<span class="at">Y =</span> y, <span class="at">X =</span> X, <span class="at">indx =</span> geog_indx <span class="sc">+</span> i <span class="sc">+</span> <span class="dv">1</span>, <span class="at">run_regression =</span> <span class="cn">TRUE</span>, <span class="at">SL.library =</span> learners<span class="fl">.2</span>, <span class="at">V =</span> V, <span class="at">cvControl =</span> sl_cvcontrol, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>  ests <span class="ot">&lt;-</span> <span class="fu">merge_vim</span>(ests, this_vim)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Now that I have estimates of each of individual feature’s variable
importance, I can view them all simultaneously by plotting:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;ggplot2&quot;</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;cowplot&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: package &#39;cowplot&#39; was built under R version 4.0.5</code></pre>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_cowplot</span>())</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>all_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">paste0</span>(<span class="st">&quot;Subtype is &quot;</span>, <span class="fu">c</span>(<span class="st">&quot;01_AE&quot;</span>, <span class="st">&quot;02_AG&quot;</span>, <span class="st">&quot;07_BC&quot;</span>, <span class="st">&quot;A1&quot;</span>, <span class="st">&quot;A1C&quot;</span>, <span class="st">&quot;A1D&quot;</span>,</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>                                      <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>, <span class="st">&quot;D&quot;</span>, <span class="st">&quot;O&quot;</span>, <span class="st">&quot;Other&quot;</span>)),</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>              <span class="fu">paste0</span>(<span class="st">&quot;Length of &quot;</span>, <span class="fu">c</span>(<span class="st">&quot;Env&quot;</span>, <span class="st">&quot;gp120&quot;</span>, <span class="st">&quot;V5&quot;</span>, <span class="st">&quot;V5 outliers&quot;</span>, <span class="st">&quot;Loop E&quot;</span>,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>                                     <span class="st">&quot;Loop E outliers&quot;</span>)))</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>est_plot_tib <span class="ot">&lt;-</span> ests<span class="sc">$</span>mat <span class="sc">%&gt;%</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">var_fct =</span> <span class="fu">rev</span>(<span class="fu">factor</span>(s, <span class="at">levels =</span> ests<span class="sc">$</span>mat<span class="sc">$</span>s,</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>                     <span class="at">labels =</span> all_vars[<span class="fu">as.numeric</span>(ests<span class="sc">$</span>mat<span class="sc">$</span>s) <span class="sc">-</span> geog_indx],</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>                     <span class="at">ordered =</span> <span class="cn">TRUE</span>))</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>est_plot_tib <span class="sc">%&gt;%</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> est, <span class="at">y =</span> var_fct)) <span class="sc">+</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbarh</span>(<span class="fu">aes</span>(<span class="at">xmin =</span> cil, <span class="at">xmax =</span> ciu)) <span class="sc">+</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;Variable importance estimates: &quot;</span>, R<span class="sc">^</span><span class="dv">2</span>, <span class="at">sep =</span> <span class="st">&quot;&quot;</span>))) <span class="sc">+</span></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;&quot;</span>) <span class="sc">+</span></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Estimated individual feature importance&quot;</span>) <span class="sc">+</span></span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;in the VRC01 data (considering only geographic confounders, subtype, and viral geometry)&quot;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAzAAAAMACAMAAADMrHKEAAAA5FBMVEUAAAAAADoAAGYAOjoAOmYAOpAAZrY6AAA6ADo6AGY6OgA6Ojo6OmY6OpA6ZmY6ZpA6ZrY6kLY6kNtmAABmADpmOgBmOjpmZgBmZjpmZmZmkJBmkLZmkNtmtrZmtttmtv+QOgCQOjqQZgCQZjqQZmaQkGaQtpCQttuQ27aQ29uQ2/+2ZgC2Zjq2kDq2kGa2tma2tpC2tra2ttu225C229u22/+2/7a2/9u2///bkDrbkGbbtmbbtpDb25Db27bb29vb2//b/7bb/9vb////tmb/trb/25D/27b/29v//7b//9v///9cW8oaAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAgAElEQVR4nO2djXvkRHrt22Ztzy7LhbSHXAI7tC9cWDJNQhLCZhRIsou1nrX1//8/UX2/JVWrJestlfzq/J4Hxq2PUtXpOlaVul1n1wAARrMrXQEAXhIwDAATgGEAmAAMA8AEYBgAJgDDADABGAaACcAwAEwAhgFgAjAMABOQaphq57lO7X+83V2+e37xdSj2dEn6oP7uaEt9on6JQ9//v7Yx++fX+VS5YApbNMz7L0Z3GXVoigKGebrbDRvmVF3PlDuZCdcRyPYM8/RPQ1105KHD/XzCQeMN83Az2MknNGsWS11nrQg2zIlfxqP6+rlDyxjm6n7exThY6jprZSOG+eXv21vNB1+0He6o7zpXf1FdsR3lXP7H17vdxR+aXz7d7X7/kzr0/dc37Rb1sz30vnn653bTB1/qktTPF3/oDcnU9UIZ5CC92x2uLvjOuoAW1J59CJUONSCGMZVpX9HK9OsaldRufPPp7vKn6Bxf51Tr1en/2dbri/tQ/u//aK+vyvrUaRIu3Wm71vri43unA72uALZhGDdAa9/ojmEsH7ruqH6Ray7e+k7oDvukcTMJOtLzhvnAl0EP8n1TdXwyq4kKiro5qUHCMLQyibp2DdNrQKhzqvWVe6Fb97Pdv/fXv/rKFkkuHbfdaU11+KSRg2DD7Pw7p/pH+2v2qDuT+Z3uu0y7Qx17rXvVQXUM1Qe+173E3hja/V+Ss9szfrlJGKY96P1t7yC/+6A7kHdBVFCnm/saJIZktDLpukaGufzp6c/ROaHOqdZHzWivePHH5r3TxZRlr0Mv3W371U/KatdN/7oC2IphLr504/+OYQ5+Ou1vSn/7l693pBO2h6qe2v5z3dgz1LE9w9j+uo8PMrv1yboz3UeXtufFQ7JQg75haGUSde0ZZt80vXMGWm+bYQqzPd1c2JZF5jD+0rTt1klu7Nm5rgA2YRgzNDBj8Y5h1Ltrf3fX+g3Xw+4d7YRu9KF6u+vByTlMYztNdJB9cbQ9dG9PiAuKujmpQd8wtDKJuvYMY3t8OCfUOdV6e7ru6m4caY5z9wl7HXpp2nZ3UpO8rgAEG4bMYZ6+NgPuL+7PGuaoZqz/ViUNE/p5u+28YfRB9kX788H+Lo8MYwrqdnNXgyHDtDv6dT1jGFfYCMOEKpqbRscw9NKptjfJ6wpgG4ZpLfMvn6m37/qcYcJMgRrGDymi2buhb5jEFF9tuz6ak/qPAaKzaQ2ShvGVSdQ1KokYpjMmGjKMH8QN3WGiSw/cYQSNxSxbMYziQXc/8zYOGMb+At039NDOuD41h+l1VDKH0aebZ0p2y7Ezh9m7q9IaJOcwvjKJukYluWtEDQh1PmGY03OYg61G+CVy7BnGHaf+6V9XAIINE8YD5slN87P7HU1m3gnDtJt+3rlOeGU+utGPkdSx5uHWz6mnZKHT0INcn2//tWN5+pTMFtS++M1P9qq0BomnZKQyqbrSknwnpw0IdT5hmPaf958mn5IdQjWiSyfa/oszWXxdAWzCMP7VxcH13L+c6jJHd9q17+SPn/r5bbxfkzAMPcj3eVWHQzihfyH9Ecg+fXLja0krk6prpyRzRdoAX4UThiGfwzjZ7LVc7dV16KXjttuTVNG96wpgG4Yxn/RffKw/in5o38arP518SvZ9+8vzk1/NUFwfqj5c/137i9s8ZNMf0H/x87BhyEG+z/vvgtFP+l1B7/9eXaDq1iD11RhSmVRdaUn+ExDaAF+FU5P+n9U3EMxx5pP+f1c/+rLMdeil47bbT/p/Sl1XAFINA55FJepDxhzAMIAAw5wDhgEEGOYcMAwgwDDngGEAmAAMA8AEYBgAJgDDADABGAaACcAwAEwAhgFgAjAMABOAYQCYAAwDwASEGubxtvMNj/rQ39aoP7+1X59/urt2q2jt7Qb3B1/qm+/uT6Aefhv9dXpN/zSq7hX/dHf+eyahVnX376xSFT5XyExcQeMLPL3EqKPXrnM83HhJnt+s+Kr99jxXMqGG6aLkSUpU2+9Otf+2nglbavNXU/qPLNv/Wfkfby9PGiZRfDXpT3Mnd6wAu2EmnHD2r8Oeb5g5zTp3VRhmkJOGebw1nfqoFn2wy7le+/fs6U5t1taxf+o+xTAT35MXapizJ8AwLwBjkDe34Q/R1V8lf37jV57w44ij/Yv7fWMNo7zTVHYlrb++s29fpf8Mf18Hw7SFXHyj3pWj/ttjfYl7+8JQ+6VTrdvMqmRv/LqS6l/zxvnCbNUeX3+zu/xT1IijO6TpF9YWoh3tbmnHTnH+BL9LX+Cdq+7Dq29vbIFGI18r/4el6WaoRpgFCsxG/Sfgh1DpZLve2aZ7qBTt/x5uPr+xqxvsrr4y7fI1jN8919rdgSgbrmrfvPriOyVl1GRvmJNaPdyo8vYPUad5EG2YVobKjaXI60ovIGE1d5K+bcgdxnlHH/BKlWCdEgxz1P1ErT+k/qpdrwB7aPwLc4h+r/WuvR7pqduZq4W+bq2WVjmQwlzVHm/1Qh2k0v4QXY1OYe2RtV6w8BDXzbfUneB36Qv46qpV0+wxvsBQ9WagGfrAsNEZplvpqF2u6V5hKoU2jD/60Nh2+RrG756T2VSvL5V5I4/tL8tDEzfZGea0Vroalf4bbPWf3S3aMHt/e6evTR+ow2y/MXcV65Jqd4hG5ubebu/w3jCm3KP6Vf3WvNKXcC/MNfdhjG8GdrXqYaYWriR1WijMVc2eGyrtD0kWpjvpwXo7UZw/Id7lq2s6YKXW0PAFRiKcbIY6kGx0hulUOm5XHY9rGyqFMYyujTrayNq2K64hLYK8AQmpKr1O7963J3q7zmmly+t0GtGGCXde+romN+vGSKpfuKdkh2aEYcwPbmsYxdgX7pr+MuZf28NMp3JLYhxCYb5qvu6+0vR6icIO6lenHUj2i/Mn+F1+RFKb8eSh6XT5Q1CoGWzGIb0xqnS3XbFjqBTGMLQ2pl1+W+fdI41ISqXlNSXFTbavBrTSP7j/+d1bNMzOG8PtqszilHq2r1cOPjskq/y70o5tL390v7LcC32i1tr80rfvMOlMxp+HcHn9rrmq9QxT9Q1DCrOuO+7juvni/AlVbBhXXdvGjmFehWnzyWYEw3Q2RleL2+Wa7iFSaMPoi7X/N+M93S5fw867RxqRlEr57ajuS2ReFo4e1Co2jNu9RcN0np8cr369Cy4xz5PdpL92AlYdw/jfTF5W33XCkGzoDmMubbpo59dcE37ZTrjDPL7+7vXbuG6+uBN3GF/dtGG47zBNaLgfMoV3IVy8c7/T7QqG6T79it6AnlStGH+yMsZNTt9haBMTd5hG+FOytGHCm2aoL759FSaI5p1MP1buzWHamWBtVkM9hLFV7Ydk6TkMMUzU4yoyUOoZxh+SLMzcsT60Lu8X15nD+Mm6q66ZIdjfxN6Bw3MYeuXExCaqdNyuzk/+dZiE+PnKobHtimsYvX30DehJ1W74Bz2Nsfvjo89r5f7nd2/GMPvwWmsZfsO5nmYNYx6m6BvN013ng0sy2VSFqKcr5reVXtZ13/gXGv+UTJXcfZJU26LNSM4W5qvWM8ypp2Tkd0AVPSqPiks9JfO/afUDXH8MLTA8OjzZDNML7Ubz+4UMKNPtck13b5Z77U4ntTELBGof2W3dd68hb0D3qkYMsy4oucOEowe1igzjd2/EMK1s+tGin2nQTyBtT/N9wy1g774aU4WvxiQ+h9F7ldBHk5hnXoSDex9g2FrUO5vKdyCFuar1DaMjwH7wI8LuBx+Hhs45/LG+pfRzGLUrXFZV13zycegUOPw5DD3Qla5Ee0Pmael2uab7mWLtlpY1p/vaaElNu8I2V5Q/2zUicVVTOJUyPnpQq9gwbrdQw6yC3uhhNt0HshEPH0WxRQPH9nZ1HjotxcOo8EvdrkQNx509ikFdY2CYjEz7LtkgusMMf3Gr2p8/9sSuQoapR61SrtuVqOG4s88wQtcYGCYjY76tPJY6fpba4+Em5OINHJveVcgw34/4kpltV6KGY84+zzldu8AwAEwAhgFgAjAMABOAYQCYAAwDwARgGAAmAMMAMAEYBoAJCDWM0GaB4gjtWUKbBYojtGcJbRYojtCeJbRZoDhCe5bQZoHiCO1ZQpsFiiO0Zw00S2iLwWxG9Qyh3QeGAZOBYabuApsGhpm6C2waGGbqLrBpYJipu8CmgWGm7gKbBoaZugtsGhhm6i6waWCYqbvApoFhpu4CmwaGmboLbJqihjle3Z87pD6RBK7WSd+PLMNcy6ZDkcNhGDCZlRsmJBD0drh8lbGG6R8Hw4DJvFzDuOQOGAYsyEoMU7kEnje3LiVHxd18e7NTGUc+JqdxQTYPNy7tKJTh44Bc1s0rdfq+d60xzdqqYVrlSldh5azDMCrqTAUUPt7aWDQaGuc3KqI0uKgMHzgX0tR2B58lCcOMQc/ySldi3azCMGZCUquMOJf4qe8yzjB7H/0R543SMvwektdJo47dpN/ccXZnusYOgDRjOnZuw5jsT5KsGwVf0xjKOLyalhEHQYcffBQ77jDnGd0jtss6DGPN6w1TDRuGxoLHhvGB0uoHl9oeHTeuWVvtNfDLOdZhGBdmy3uHgWEAO6swjO/9zhum01d9w0yfw7j9MAzgYBWGMc/AaIp6eEq2jwwz7SlZWyqekgFWyhrGTF325nOY1iPBG+2uyx/aLUf1OQwxjPuQJRjGl9H7HOaGfn7jnpJdhFhdGAZMZs1fvjQzmWdzNiYbhgGTWadhdF/3XxebU8gQMAyYzDoNYx40n+nv54BhAD8rNcwiwDBgMjDM1F1g08AwU3eBTQPDTN0FNg0MM3UX2DQwzNRdYNPAMABwI7RnCW0WKI7QniW0WaA4QnuW0GaB4gjtWZj0C6X4u1e8AnmAYYRS/N0rXoE8wDBCKf7uFa9AHmAYoRR/94pXIA8wjFCKv3vFK5AHGEYoxd+94hXIAwwjlOLvXvEK5AGGEUrxd694BfIAwwil+LtXvAJ5gGGEUvzdK16BPMAwQin+7hWvQB5gGKEUf/dmV2B++uvTnV3V7+lOrROrVmG6HiwpXVgEDCOU4u/eAoY5m/7qFklW/5p1+aeW1AOGEUrxd6+sYQ7232tf1OAasjDM5in+7jEaZkb6q/5H33CqaDRGlyd/1EWo9cuNZ9zlXn/TlqLKostpvjzDIO9oFMVF4jPMjPRXksB3/HAX4pGjA+3kxc1hwuXaCugCauKYF2cYJOqNo7hGbIaZk/6qZvumJN39m+O+6R8YGya+HB3Incv3zJMnChZibn+dC5th5qS/Nir4kiwwbvt/fGBsmO7lOlMf3GGEUlwjPsPY3wDPSX/Ve6rQ56134gM7hoku196MdpjDbIHiIjHfYZpnpb+qUn69C9N9+2z5/B2mIXllavQ3plnFJQczKP7uMc5hnp/+ql59+8qOsRo/JCMH7r1xgm+a+LrRA2cYRijF3z3ep2TPTH9V3vjQlHPU03/7mMwd+HR3dd8Oug62JP+UzF9O329q3GHkU/zdm28YM5eYlf7aqJP3obxw4zEH6i/MvFEe7HwO4y6nDyR+gWGkUvzdy12BmemvzwWGEUrxdy9fBVjSX58LDCOU4u9exgpwpL8+FxhGKMXfveIVyAMMI5Ti717xCuQBhhFK8XeveAXyAMMIpfi7V7wCeYBhhFL83StegTzAMEIp/u4Vr0AeYBihFH/3ilcgD0KbBYojtGcJbRYojtCeJbRZoDhCe5bQZoHiCO1ZmPSvAoFaC2ySAoZZBQK1FtgkBQyzCgRqLbBJChhmFQjUWmCTFDDMKhCotcAmKWCYVSBQa4FNUsAwq0Cg1gKbpIBhVoFArQU2SQHDrAKBWgtskgKGWQUCtRbYJAUMswoEai2wSQoYZhUI1HrxJs0PkfWrbe5OFwXDrAKBWq/QMGdDZEeUAcOsAoFavyzDHMaWAcOsAoFaFzTMjBBZX4Y9mYRkGvgNg8CjZyBQsnKGmREiSw2jj/tHH5JpYTcMIvWeg0DFihlmToism/Tv/XGVDr7QU5xz2aH8OaXgJDl7UhmKGWZOiCy9w4Qwv6yBSkLf/swIVKycYezvoOeEyPYNo5LL6KMAzGFWgUDJCt9hmmeFyCYMU1/+iT5Yw1OyVSBQ64JzmOeHyCYM83j7DzTrDIZZBQK1LvuU7JkhsgnDNMfdNbkKDLMKBGq9vGHM1GVWiKx7Skbcpl01qlkC38TVIlDrtTWJKUQWhlkFArVeT5NYQ2RhmFUgUOsVNYkzRBaGWQUCtRbYJAUMswoEai2wSQoYZhUI1FpgkxQwzCoQqLXAJilgmFUgUGuBTVLAMKtAoNYCm6SAYVaBQK0FNkkhtFmgOEJ7ltBmgeII7VlCmwWKI7RnCW0WKI7QnoVJf2mkyiy0XTBMaaTKLLRdMExppMostF0wTGmkyiy0XTBMaaTKLLRdMExppMostF0wTGmkyiy0XTBMaaTKLLRdMExppMostF0wTGmkyiy0XTBMaaTKLLRdMExppMqctV2PtzsXGmawiS+NDn49c2rvAJVAZpZhOpka64FhSiNV5pztMqu3HklsizfMmf6eolKlPdxcD4RgBmCY0kiVOWe7jnp58Ke7sEr4DMM8vHprTtzDMC8BqTJnbBdxSoi0UFmvJt/16iu1u7p+ePWt3tb4mFh/RhiEOfe1x1z9V5wa67JlX39DRn9chkGM0nORqlveIZlzTDCMT4I96HXHn+7abW2/16M3FxPrztD3I7sqv190ue6kxoZsWZpFzmQYBPU9G6myZW2XDwoPhlHdvlJJsGZU1Q607Larex8T2zSNd5TDD8FsEplLg42zZXWLzvTyzDGowJKjQ62A3O16utu1t4A4ZcyFibWjrNYnfpuPiVXnGVMEx/QNY4P+omzZMc3CHWYRpMq2QLuO5oaiDaNn7u3/TQbS5bvj3s7mlWHsryZvGOU2N4fpD8msYdxJWQyDOcyzkapbxna5R2J1CAqL7zCPr797/ZYYhjx/JmljdmuY9N/37zBN97kbnpKVRqrMCzwlcxOM1i1kvqJvIB+2E3Wz7Wi3OeLM2IYM1chjZRpFDsOsC6ky531Kph5c1bt9a42r+3Z8ZZ6SmYxX7Zyd9pHd5mNi1bl60q9+9LcQ+sElSY2NsmXHNEvqO7kypMqc/6sxusOrn964z2H05//KTHo0Fra5mFhz6sFkkoVxWvhUJkqNpdmyY5ol9Z1cGVJlLtquh4/u6ffLGIFhSiNV5qLtqtS4DIYRiVSZC7br4UZ/Ng/DiESqzELbBcOURqrMQtsFw5RGqsxC2wXDlEaqzELbBcOURqrMQtsFw5RGqsxC2wXDlEaqzELbJbRZoDhCe5bQZoHiCO1ZQpsFiiO0ZwltFiiO0J6FSX9utiqj0HbDMLnZqoxC2w3D5GarMgptNwyTm63KKLTdMExutiqj0HbDMLnZqoxC2w3D5GarMgptNwyTm63KKLTdMExutiqj0HbDMLnZqoxC2w3D5GarMgptNwyTm63KWKjdueJiHTBMbrYqY5l254qL9cAwudmqjGXanSsu1gPD5GarMhZpd6642BByOc4wiEt6PltVrtSQLE9crL/AKMMgkG8GWxWuULszxcWqf85FkmZPQ90ImXrG2inX7hxxsb5w3GFys1XhirabPS7Wl4w5TG62qlyRdmeLi/UH4SlZbrYqY9GnZOxxsR4YJjdblbHUU7I8cbEeGCY3W5Wx5FdjMsTFOmCY3GxVxpW2e25cLAyTm63KuNJ2z42LhWFys1UZV9nu+XGxMExutiqj0HbDMLnZqoxC2w3D5GarMgptNwyTm63KKLTdMExutiqj0HbDMLnZqoxC2w3D5GarMgptt9BmgeII7VlCmwWKI7RnCW0WKI7QniW0WaA4QnsWJv0sQKseQiWBYViAVj2ESgLDsACtegiVBIZhAVr1ECoJDMMCtOohVBIYhgVo1UOoJDAMC9Cqh1BJYBgWoFUPoZLAMCxAqx5CJYFhWIBWPYRKAsOwAK16CJUEhmEBWvUoufIlUyjskSzt74BhWIBWPUqtrcwYCnu0i5hhbWV2oFWPMpKwhsIaw0TxMAPNQibMBCBVj6JxFw1PKKwxDLXf6WYhdWwKUKpHqSEZXyisM4z7dziBcYn0R0Hk7AQvk0KSMIbCesNUZCPuMCxAqR7lJOEKhZ1mGMxhpgCpehSVhCUUtjsk0+ApGQvQqkcRSZhDYadM+tEJpgCtehR9SsYTCjvtsTI6wQSgVY9ST8kYQ2HdB5ckRBmG4QFa9Sj51RimUFh8NSYb0KrHSiVBKOwqgFY9VioJQmFXAbTqsUpJEAq7EqBVD6GSwDAsQKseQiWBYViAVj2ESgLDsACtegiVBIZhAVr1ECoJDMMCtOohVBIYhgVo1UOoJEKbBYojtGcJbRYojtCeJbRZoDhCe5bQZoHiCO1ZmPSzAb0ihMoBw7ABvSKEygHDsAG9IoTKAcOwAb0ihMoBw7ABvSKEygHDsAG9IoTKAcOwAb0ihMoBw7ABvSKEygHDsAG9IoTKAcOwAb0ihMoBw7ABvSKEygHDsAG9IkqufMkUCmvX8idr98MwjECviFJrKzOGwuo1muPSYBg+oFdEGTlYQ2HtqWpZc78NgUpsQK6IonEXDUsobGWN8lcywjvZLET2TQVqRZQakvGFwkZBSk2DUFhuMvWBF0ohORhDYc3ODrjDsAG1IsrJwRUKO80wmMNMBXJFFJWDJRS2OyTT4CkZG9AroogcvKGwbtJfkxAyGIYN6BVR9CkZTyjstMfK6AATgV4RpZ6SMYbCmg8un+7wwWUWoFdEya/GMIXC2tLw1Zg8QK+IlcqBUNjVAL0iVioHQmFXA/SKWKUcCIVdEdArQqgcMAwb0CtCqBwwDBvQK0KoHDAMG9ArQqgcMAwb0CtCqBwwDBvQK0KoHDAMG9ArQqgcQpsFiiO0ZwltFiiO0J4ltFmgOEJ7ltBmgeII7VmY9LMArXoIlQSGYQFa9RAqCQzDArTqIVQSGIYFaNVDqCQwDAvQqodQSWAYFqBVD6GSwDAsQKseQiWBYViAVj2ESgLDsACtegiVBIZhAVr1ECoJDMMCtOohVBIYhgVo1aOUJJypsEe9tD9dKRaG4QFa9SgkCWsq7FGvYlZhbWV2oFWPQpKwpsIaw0TBSghUYgFS9SgjCW8qrDMMMdrJZiGybwpQqkexIRlfKqwbktkSh5NMF4lRlUPOPvAyKSUJYyqsnfRHeRe4w7AApXoUlIQrFdbeYcJNq8EchglI1aOsJCypsNYwqjBfMJ6SsQCtepSRhDcV1hqmgmG4gVY9yj4l40mFdXcYhMJyA616FHtKxpgK6+YwYx4roxNMAVr1KPrVGKZUWHw1JhfQqsdaJZmZCgvDsACteqxVkpmpsDAMC9CqxzolmZ0KC8OwAK16CJUEhmEBWvUQKgkMwwK06iFUEhiGBWjVQ6gkMAwL0KqHUElgGBagVQ+hksAwLECrHkIlEdosUByhPUtos0BxhPYsoc0CxRHas4Q2CxRHaM/CpJ8PCEYRqgYMwwcEowhVA4bhA4JRhKoBw/ABwShC1YBh+IBgFKFqwDB8QDCKUDVgGD4gGEWoGjAMHxCMIlQNGIYPCEYRqgYMwwcEowhVA4bhA4JRhKoBw/ABwSgLqMGZ/9qodS59NN/Db981Ph4mOhKG4QOCUfKrwZr/qgIxPnPmsyExR7uGGYmHgWEYgWCU/Gqw5r+qUIsfXVaGvW/ZVfvrcSnKCFSaCvSiZFeDN/9VFWdLrHf7mhqGWvJ0sxDZNxnIRVliSMaY/6rvI5W7l0SGcf8Op5nmzVCVSZ5+8UJZQA3O/FftCnNI0zXMqAQy9IDJQC7KMmqw5b/aTDK75RmGwRxmMtCLspgaPPmvFd2bHpKdaxbe/4lAMEp2NVjzX+3E/vHWR2Q2Eyf9eP8nA8Eoiz0lY8l/dW6y0/76GY+V8f5PBYJRlnhKxpf/6kZd9ilaHX1wuScXhWH4gGCUpb4aw5L/Gr5TY6b91jB0WnO+WXj/JwLBKCtQY2b+axIYhg8IRlmBGjPzX5PAMHxAMEpxNWbnvyaBYfiAYBShasAwfEAwilA1YBg+IBhFqBowDB8QjCJUDRiGDwhGEaoGDMMHBKMIVQOG4QOCUYSqIbRZoDhCe5bQZoHiCO1ZQpsFiiO0ZwltFiiO0J6FST8fEIwiVA0Yhg8IRhGqBgzDBwSjCFUDhuEDglGEqgHD8AHBKELVgGH4gGAUoWrAMHxAMIpQNWAYPiAYRagaMAwfEIwiVA0Yhg8IRhGqBgzDBwSjCFUDhuEDglGWWvkyYyisXd+frN0Pw3ACwShLrK2cORRWr9scXwGGYQSCUfKrkT0U1hanljr3RyFQiQ/oRVks7qLJFgpbWaP8lYz6TjYLkX2TgVyUJYZkeUNhoyClpkEoLDvsXeIls4AamUNh/SsK7jB8QC7KMmrkDIWdZhjMYSYDvSiLqZEtFLY7JNPgKRkfEIySXY38obBu0l+TEDIYhg8IRlnsKVm+UNhpj5Xx/k8FglGWeEqWORTWfHD5dIcPLvMAwShLfTUmYyisvQK+GpMJCEZZgRoIhV03EIyyAjUQCrtuIBiluBoIhV07EIwiVA0Yhg8IRhGqBgzDBwSjCFUDhuEDglGEqgHD8AHBKELVgGH4gGAUoWrAMHxAMIpQNYQ2CxRHaM8S2ixQHKE9S2izQHGE9iyhzQLFEdqzMOmfARQaQKg4MMwMoNAAQsWBYWYAhQYQKg4MMwMoNIBQcWCYGUChAYSKA8PMAAoNIFQcGGYGUGgAoeLAMDOAQgMIFQeGmQEUGkCoODDMDKDQAELFgWFmAIUGECoODDMDKDQAuzisEbC1WfMyWtHfcNQb7OqwCIVlBQoNwC0OawSsWlHZr+bvluw3mFWWzaLkCIXlBQoNwC0OZwTs093el6gTy+h1tGFcHoA5GqGwPNlmkZMAABb/SURBVECgAZjFYY2ANU6wRnGxlxZnmANCYdmBPgPwD8n4ImBtyJIxzDG6wbgh2TVCYTPA1hsEwi4OYwSsmb7UNikjTrI0k/4djYgd1Sx0iPNAnwFyiMMVAUsNEyX5Ne4Oo+5nCIXlBgINkEkclghYOiQ7Rk+N/ev2OgiF5QYKDcAsDmsELJn0924j1jBqJ0JhmYFCA2R6SsYSAUseK/fiY9wdRheGUFhWoNAA/E/J+CJgyQeX3SmMn8PouxdCYVmBQgPk+WoMSwSs2Wl+jj+1bDpfjUEoLCtQaIDFxckRAdsHhpkBFBpgcXFyRMD2gWFmAIUGWFiceRGw+mszOzpmOwUMMwMoNIBQcWCYGUChAYSKA8PMAAoNIFQcGGYGUGgAoeLAMDOAQgMIFQeGmQEUGkCoODDMDKDQAELFEdosUByhPUtos0BxhPYsoc0CxRHas4Q2CxRHaM/CpJ8N6BUhVA4Yhg3oFSFUDhiGDegVIVQOGIYN6BUhVA4Yhg3oFSFUDhiGDegVIVQOGIYN6BUhVA4Yhg3oFSFUDhiGDegVIVQOGIYN6BUhVA4Yhg3oFSFUDhiGDegVkWflS+ZQWLOkfzfV4ui3YOXLjECvCP61lTOEwup1k6tdHGvx8Ooz68tqp1c5vxwT2YcOMBXoFcEtR5ZQ2Cjs0lFd/mhK9qv3E0MhUIkNyBWRKe6iYQ+F7a7g317JXsxlLVXEjyebhci+qUCtCP4hWaZQ2G4srLKPzsow9yHSokFPZAtSlQtb3xABuxyZQmFtCkzg6PJgkyM93GHYgFoROeTIEQpLbl0am2HWHmwMo/JiiNcwh2EDckVkkoM9FLZzf9FTH3Oij7+sRxkGHWAi0CuCWY5cobBVxy92vv94ex0m/TBMFqBXRKanZMyhsNWuM09xRjPPDA7ummOahQ4wDegVwf+ULEMorHuMFnB3Fb3H3H6Ou1Gfw6ADTAR6ReT5agxzKKydsIThW/i6jX7W3Ps6DgzDB/SKWFwOhMK+MKBXxOJyIBT2hQG9IhaWA6GwLw7oFSFUDhiGDegVIVQOGIYN6BUhVA4Yhg3oFSFUDhiGDegVIVQOGIYN6BUhVA4Yhg3oFSFUDqHNAsUR2rOENgsUR2jPEtosUByhPUtos0BxhPYsTPrnA6FSCFUFhpkPhEohVBUYZj4QKoVQVWCY+UCoFEJVgWHmA6FSCFUFhpkPhEohVBUYZj4QKoVQVWCY+UCoFEJVgWHmA6FSCFUFhpkPhEohVBUYZj4QKoVQVWCY+UCoFIVUOUYRrknqw4mQv0pHlvlMS7Wcs176EkvF8gKhUqzWMC5+KbHDLLRsY8r0vyYNgADDzAdCpXiJhjnYf699UXWcFzvULAQqjQU6pShuGBsK+3j75tYtWb67+OZChcZe/eXWr1nemGXK9yES0GZe6htOdd0p/2SzENk3GsiUorRhKp8Ya0NelQ3qnYlf8hsVJjHjOtx2fFJTW9yHO5/FPJxkmik4VSQ5O8CLpbBhfChsiF/SdxlnmL1fh9mkK7kgM7PlunHhsKq4IwmRwR1mPpApRWHD+FBYF/BnEy2dYQ5+zmJ8447UqDA/sqz5uAQy+GUs0ClFacPYu783TDVsmPZFMIz6qQouoZEAeEo2HwiVorRhXHDFc+4wbSm/3oXpPn22DMPMB0KlKD6HoTmwPnO56humP4dRr759ZYd0DUJhuYFQKdbwlMzN8bU3wlOyfWSY/lMyF8ncmKTlcZN+9IPRQKgUpQxjpi57HwobvNHuuvyh3XJUn8MQw9jPYaJPMyv3LFmVRz/khGHmA6FSrFOV3if3U4Fh5gOhUqxNFT0dcV8Xez4wzHwgVIrVqaIfNM/OWIZh5gOhUghVBYaZD4RKIVQVGGY+ECqFUFVgmPlAqBRCVYFh5gOhUghVBYaZD4RKIVQVGGY+ECqFUFWENgsUR2jPEtosUByhPUtos0BxhPYsoc0CxRHaszDpnwtkSiNUFxhmLpApjVBdYJi5QKY0QnWBYeYCmdII1QWGmQtkSiNUFxhmLpApjVBdYJi5QKY0QnWBYeYCmdII1QWGmQtkSiNUFxhmLpApjVBdYJi5QKY0QnWBYeYCmdKc12V+fuuoMsy17GL+pw43F0pfKwKGmQtkSsNhmLP5reMNM3zcyQv1gGHmApnSZDbMYWwZo47jMAwClcYBldJMMcyM/FZfhl1R3P/w8Eqdvu9dKzrarlT+ubmQHZK52rz+pr2IuhRdL/NksxDZNxKIlGaCYWbkt/oy3B7/Q9vTD/pFfFzTL8dOXtwcJtSmPUevyGxLGQ40zRmiKotp/WgzjDfMnPxWV4bf439Qfb7t/Xa/m/Tvm345sWHi2vRW+8cdZi4QKc14w8zJb3Vl+D2dH1xyX3yHicuJDdOtTccxmMPMBSqlmWAY+9v/OfmtsWF8Mp/6QWfuDRnGldMxTFSb9ma0GzeHQU8YCWRKM/UO0zwrv3XgDnPWMEN3mIYGkh0vEArLB2RKM2UO8/z81nNzGLc/NgwpZ++NE3xDatP5CYaZD2RKM/Ep2TPzW4eekrWlnntK9nR3dd8Oug72Qv4pma+Nvt/UuMMwApnSjDCMf3D1/PzWUEbvc5gb+vmNe0rmur47+vF2t3ujLNr5HMbVRh9I/ALDzAYypZmty8z8VvskmhsYZi6QKc0MXVjyW2GYlQKZ0szRhSO/FYZZKZApjVBdYJi5QKY0QnWBYeYCmdII1QWGmQtkSiNUFxhmLpApjVBdYJi5QKY0QnWBYeYCmdII1UVos0BxhPYsoc0CxRHas4Q2CxRHaM8S2ixQHKE9C5P+3GxVRqHthmFys1UZhbYbhsnNVmUU2m4YJjdblVFou2GY3GxVRqHthmFys1UZhbYbhsnNVmUU2m4YJjdblVFou2GY3GxVRqHthmFys1UZhbYbhsnNVmUU2m4YJjdblXHhdqslLHd06b+wzFJ9Zr2lVFbf0WeXNQ+/pQsKwjC52aqMy7bbLKJMl9n3hhmXXRnz8OozZ75OQgwMk5utyrhsu4/X6v9Pd9d+yyzDVJc/3rjlz3cjDYNAJR62quKi7SZOCZkZn9+4ANmrr9Tu6poExVY+v8+cEYW/tsXZEuvdvh5nGET2MbFVEZcekjnHBMP4cNeDXtj86e4QgmJd8qs7g4a/mnyLyi/07wwzHGnKGZu6bXL1kZWzcLt9EnkwjA6FVeGuJiXp4VUIivXJr409I76NqDQZvxg67jDLslURl2/3051KcoljzFxaWTvHaX3it/nkV3WecRSxhQ0vs1tGGgZzGCa2qmKRdh/NDSWEwrb/N0lil++O+8bnXvrkV3WSPoCGv1Z072jDbPadZmarMi7abvdIrA65f/Ed5vH1d6/fEsPQULEQZ2a22vm+DgBsYJil2aqMRZ6S1eoOs7dxyn6+om8gH7bzEh8UGz1q7sbAOjfZaT8MsyxblXHpp2Qq9bXe7RuX8+pDYc3svTK5ly4o1iW/qnN92Lh1SogyN5mZMMyibFXGEl+N0R3e5ryGUNijMpMejZGgWJv8ak490PDX8J0aM+2HYZZlqzKurN0PH92zxPjBMLnZqowra3elhlcwzAtgqzKuqt0PN3peAsO8ALYqo9B2wzC52aqMQtsNw+RmqzIKbTcMk5utyii03TBMbrYqo9B2wzC52aqMQtsNw+RmqzIKbbfQZoHiCO1ZQpsFiiO0ZwltFiiO0J4ltFmgOEJ7Fib9PECsLkIVgWF4gFhdhCoCw/AAsboIVQSG4QFidRGqCAzDA8TqIlQRGIYHiNVFqCIwDA8Qq4tQRWAYHiBWF6GKwDA8QKwuQhWBYXiAWF2EKgLD8ACxughVBIbhAWJ1yauIW851gPpwIq2v2oXE1x4mAlav5W8WinULYlpgGB4gVpfShnE5Sokdp+1ic2Ke7lQEmQo1U8stR0v9wzA8QKwuKzbM6dX8bASsWfCvunz3dKeX+w9RswhUYgJadVnKMDbd9fH2za1be3x38c2FSn+9+sutX3y8MeuN70O2nzvybYiKjSNg2zuLd875ZiGybxKQqstChql89KsNclVL7tc7k6PkNypM9MU1yU+yR4ao2CZaq7/dbxOYzLbhyNIF0lJFkaVbvGSWMYxPdw05Svou4wyz9wsqm9GVSyRr3PbjRYiKbRpqGBU2Y6YvdBKDOwwPkKrLMobx6a4uqc90+NoZ5uDnLMYf7sjGWcOPu+pO3ljt5vwjDYM5zCSgVZeFDGNv8N4w1bBh2hfOMP5In3ypC3TZyXpSEw3JzjULfWACEKvLkneYpmnm3GEShqnMpzATJv3oA5OAWF2WmsPQQFcfnlz1DXNiDlO5OcyRzmEq+whgymNl9IEpQKwuCz4lc3N87Y3wlGwfGWboKZmLim2sYWwcbIMPLrMBsbpkNoyZuux9umvwRrvr8od2y1F9DkMMYz+HIR9c2iNJVKw1TGVKV0ap8NWYLECsLkUViZOPzxw5KcgPhuEBYnUppIju/YNfF+sdCcMUAGJ1KaWIftA8ygHuSBimABCri1BFYBgeIFYXoYrAMDxArC5CFYFheIBYXYQqAsPwALG6CFUEhuEBYnURqggMwwPE6iJUEaHNAsUR2rOENgsUR2jPEtosUByhPUtos0BxhPYsTPq5gWwGoTrAMNxANoNQHWAYbiCbQagOMAw3kM0gVAcYhhvIZhCqAwzDDWQzCNUBhuEGshmE6gDDcAPZDEJ1gGG4gWwGoTrAMNxANoNQHWAYbiCbQagOMAw3kM3Ar8Pj7c6Hh2nC+kj1mYWS+jF9JOzV5MBSjjY11q6vuSP5gDAMN5DNwK6DWf34SBZu9YYZiq08UVhYM9nkwFIeXn1mNiWSNGEYbiCbgV0Hs4b+011YSv/5hiGr8tfxXUtRXf5oSp5kGAQqPQ+oZuDWgTglRFt8fuNyXq++Urur65Dw6uJi/RnqsF0UdaGX7993F2Jur2QvNsUwiOx7JhDNkGFI5hwTDOMTYQ96/fGnu0NIeHVxse4MbRKbahEli3UNU/sk2dgww2GmGfNThcPXRV40/Dr4wPBgGJ3mqhJhTXhS6wOf8OrjYht7BvVFlF3ZNYyyiTnbTfrJ0ua4w3AD0QxZdHi6U8+24rQxFyrWzkhan/htPi5WnWccFYwxZBgbSKY2Yg6zAFDNkEuHo7mhaMPogVX7f72h7ffHfeMDK31crDpJH9C6zc9hBoZkVTgRT8kWALIZuHVwj8TqEM8X32EeX3/3+i0xDA0OCzF9ZmsU9hobxs73VbgfDLMEkM2Q6ylZre4we93nyXxF30A+bPu3T3iNHjXH2bGdsNfYMM5oatoPwywAZDNkeEqmum/dzsCf7q7u2/HVwae5mim6jgoPCa8uLladqyf96kdnBxr2GhvGmUQ5D4ZZAMhmyPTVGN3J1U9v3Ocw+vN/ZSY9GiMJrzYu1px6MIljfpxGwl7r9Ndt2smSe0pGRncwDDeQzbC8Dg8f3U/M33sGMAw3kM2wvA6VGpfBMC8NyGZYWoeHGz3heKZh9NdmOqOvJDAMN5DNIFQHGIYbyGYQqgMMww1kMwjVAYbhBrIZhOoAw3AD2QxCdYBhuIFsBqE6wDDcQDaDUB2ENgsUR2jPEtosUByhPUtos0BxhPYsoc0CxRHas4Q2CxRHaM/KvYQK2BihZxXs1WVYQ4tRB8MLrMMaqrwsa2gx6mB4gXVYQ5WXZQ0tRh0ML7AOa6jysqyhxaiD4QXWYQ1VBuDFAMMAMAEYBoAJwDAATACGAWACMAwAE9iCYWq6LJN/UZ9frCl3HfQiobvrgdPy1cGn7BbUwdWhoA46K2KfqNkpNmAYukBzeBFtLVQHk2GwFJ0W2yCegjr4OpTT4elO5dgpr47VQb5hoggA/yLaWqgOvVC15ergU3YL6hCSfsvp4ANVRusg3zBRyIx/EW0tVIemWmwU0q2DT9ktqENI+i2og6nIxdvROmzAMDTGzL+IthaqQ3P8cBclcy5Xh8b9WFAHX4fCOugEiNE6yDdMHJTpXkRbC9Xh8VatM31cqKf0Wqx7R0EdfB0K66DDjEbrAMOUq4Pdt9Bv9/UapvfjwnVwc34YRrPiIZnZlzn5I1mHxv24iiGZ2VdIh1oPBjEk86x40m/2LfRMtdfi4pP+JjZMGR0qM3nCpN+z3sfKNl56oc7aa3Fd/LFyZNoyOlQ24R6PlQPr/eBSvz9LTXZ7La7Lf3DpnpIV08GkeadqdooNGMYly5pEdB8zWy36lZB0HVSc7TIj914d/K/0gjr4OhTToTJrwqiXI3XYgmEAYAOGAWACMAwAE4BhAJgADAPABGAYACYAwwAwARgGgAnAMABMAIYBa+DhZsnP+mcAw4AV8Hh7WPAbbXOAYcAKqK/um6e7l3CLgWHASlB3mfUDw4CVUKm/7F89MAxYB0v91edMYJhFsUs9dn50PN1Fv2SP/oDOjpPbhvnbtMOHyjl38RGXqm0+8Qdf6JKqFzHlh2GW5ujX36r6K3HlNcx//pbnV7gq58zFx1yq9pHe+m/qXsb9BYZZmocb29P0qr7DDBtmMkemPjminDGXqu3nLr/ctEIsu7ryHGCYZfE+ebg5u+DCNgyjfzjqWw2ekoEebiR21N3j59/tdhdfqM8grqvd5b9rX7htbbf7j+93u9//5Azz/mu7Q6O3Ha9+/Xp38Yfmqd31SXSKOvxmt/tYn90WfnFjBj/hilf/9ak6VR356W73kT2HXoK+fvr+Rhes8yGukxd3ZZtDUifTqUpkmJcDDLMwZl1U+49dg2HfdsMPbnZXv6pu6Le1vf//2hUadP9U3x4hMSq2z36ltn151zvFHX75zhT+m0/1ueSK/jrmSLPgUXQJ+vpoV4uIDBNf3JVtDZM4OWUYPSR7OcAwS3M0i5KqHvZ4e9n+1n1ovdP2sb3xQNjWdrPLf2x/Oe+urTl2f3evXtrfx3bb1U9tl1P//3mnX1/80ZzS/vjJvTtb39XUOCm64vW9jkbRu5/+SZXbuQR5bQz+szHlu+TFac2V+5InB8Kk/5NF9Z8JDLM0evLydGdH+f/zr///dzvVfc2qevruY7dZa6ldaoed9LgFimyfNesF+ZPDKfZOZs42q3+ZS0ZXVEc93l7TqpFLkNePtxcf/+uf9dZgmM7FSc3bbemTA/6x8pf8GmcEhlka3cNsb7KjFtV9VYejIy/3e1qPYoxhbA/zj9ncIeTkcIpbos6e3VjDJK4YFrPrXoK+1uMtO7V6l754XPP0yQE9JHt/Z2ZRLwcYZnHU6qRHl3H5f774t/++pd03bDtlGHtvepZhUldMGMZeInr9318TN6Qu3ql5+uSAmcPY4eLLAYZZnHYIZMdLps88Rt03bOsNyeKelTZMekjmDZO6Ih2SxZfovv7bL5+25Z8yDK25Nkzq5ICd9LfDtZc054dhCnC8/MF0llrNu99/uosN47a1s+bf/BQm/U/t6EVNnW+iOUzXMP6UaNJvDKNWD05csf0l/6V6WKUO7F7Cv27HkH/WI6i3upy0YULN9SGpkwPuKVkd33jWDgyzPO1gxYx5TNy2GrREAxs3kLHPiN0vdDvGcb3uxB3md51HxK5366e+16kr2iPJo2jfsclr82RYObHyj5V7QzJX84o8Vu6c3P8c5viiBmUwzPKEcbv6xPCDL49umqH/77epTyHbof/Hbof+IFB/EmlLSc5h3Cn2c8NP/uwfYT2qX/6pK+pL/sZ/cBkuQV8//fONfaKlyvk1dfFQc32p5MkJw7ysQRkMIwqur7+AU8AwooBhcgPDiAKGyQ0MIwoYJjcwDAATgGEAmAAMA8AEYBgAJgDDADABGAaACcAwAEwAhgFgAjAMABOAYQCYAAwDwARgGAAmAMMAMIH/BfqcbwFGlk4/AAAAAElFTkSuQmCC" /><!-- --></p>
</div>
</div>
<div id="estimating-variable-importance-for-a-group-of-variables" class="section level2">
<h2>Estimating variable importance for a group of variables</h2>
<p>Now that I have estimated variable importance for each of the
individual features, I can estimate variable importance for each of the
groups that I mentioned above: biological and behavioral features.</p>
<p>The only difference between estimating variable importance for a
group of features rather than an individual feature is that now I
specify a vector for <code>s</code>; I can use any of the options listed
in the previous section to compute these estimates.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get the estimates</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">91011</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>subtype_vim <span class="ot">&lt;-</span> <span class="fu">vimp_rsquared</span>(<span class="at">Y =</span> y, <span class="at">X =</span> X, <span class="at">indx =</span> <span class="dv">5</span><span class="sc">:</span><span class="dv">15</span>, <span class="at">SL.library =</span> learners<span class="fl">.2</span>, <span class="at">na.rm =</span> <span class="cn">TRUE</span>, <span class="at">env =</span> <span class="fu">environment</span>(), <span class="at">V =</span> V, <span class="at">cvControl =</span> sl_cvcontrol)</span></code></pre></div>
<pre><code>## Warning in cv_vim(type = &quot;r_squared&quot;, Y = Y, X = X, cross_fitted_f1 =
## cross_fitted_f1, : Original estimate &lt; 0; returning zero.</code></pre>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>geometry_vim <span class="ot">&lt;-</span> <span class="fu">vimp_rsquared</span>(<span class="at">Y =</span> y, <span class="at">X =</span> X, <span class="at">indx =</span> <span class="dv">16</span><span class="sc">:</span><span class="dv">21</span>, <span class="at">SL.library =</span> learners<span class="fl">.2</span>, <span class="at">na.rm =</span> <span class="cn">TRUE</span>, <span class="at">env =</span> <span class="fu">environment</span>(), <span class="at">V =</span> V, <span class="at">cvControl =</span> sl_cvcontrol)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co"># combine and plot</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>groups <span class="ot">&lt;-</span> <span class="fu">merge_vim</span>(subtype_vim, geometry_vim)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>all_grp_nms <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Viral subtype&quot;</span>, <span class="st">&quot;Viral geometry&quot;</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>grp_plot_tib <span class="ot">&lt;-</span> groups<span class="sc">$</span>mat <span class="sc">%&gt;%</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">grp_fct =</span> <span class="fu">factor</span>(<span class="fu">case_when</span>(</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>      s <span class="sc">==</span> <span class="st">&quot;5,6,7,8,9,10,11,12,13,14,15&quot;</span> <span class="sc">~</span> <span class="st">&quot;1&quot;</span>,</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>      s <span class="sc">==</span> <span class="st">&quot;16,17,18,19,20,21&quot;</span> <span class="sc">~</span> <span class="st">&quot;2&quot;</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>    ), <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;1&quot;</span>, <span class="st">&quot;2&quot;</span>),  <span class="at">labels =</span> all_grp_nms, <span class="at">ordered =</span> <span class="cn">TRUE</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>grp_plot_tib <span class="sc">%&gt;%</span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> est, <span class="at">y =</span> grp_fct)) <span class="sc">+</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbarh</span>(<span class="fu">aes</span>(<span class="at">xmin =</span> cil, <span class="at">xmax =</span> ciu)) <span class="sc">+</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;Variable importance estimates: &quot;</span>, R<span class="sc">^</span><span class="dv">2</span>, <span class="at">sep =</span> <span class="st">&quot;&quot;</span>))) <span class="sc">+</span></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;&quot;</span>) <span class="sc">+</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Estimated feature group importance&quot;</span>) <span class="sc">+</span></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;in the VRC01 data (considering only geographic confounders, subtype, and viral geometry)&quot;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
</div>
<div id="types-of-population-variable-importance" class="section level2">
<h2>Types of population variable importance</h2>
<p>In this document, I have focused on one particular definition of
population variable importance that I call <em>conditional</em> variable
importance. For a further discussion of what I call <em>marginal</em>
variable importance and <em>Shapley population</em> variable importance,
please see <a href="types-of-vims.html">“Types of VIMs”</a>.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="unnumbered">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-breiman2001" class="csl-entry">
Breiman, L. 2001. <span>“Random Forests.”</span> <em>Machine
Learning</em> 45 (1): 5–32.
</div>
<div id="ref-friedman2001" class="csl-entry">
Friedman, JH. 2001. <span>“Greedy Function Approximation: A Gradient
Boosting Machine.”</span> <em>Annals of Statistics</em> 29 (5):
1189–1232.
</div>
<div id="ref-hastie1990" class="csl-entry">
Hastie, TJ, and RJ Tibshirani. 1990. <em>Generalized
<span>A</span>dditive <span>M</span>odels</em>. Vol. 43. CRC Press.
</div>
<div id="ref-vanderlaan2007" class="csl-entry">
Laan, MJ van der, EC Polley, and AE Hubbard. 2007. <span>“Super
Learner.”</span> <em>Statistical Applications in Genetics and Molecular
Biology</em> 6 (1): Online Article 25.
</div>
<div id="ref-magaret2019" class="csl-entry">
Magaret, CA, DC Benkeser, BD Williamson, et al. 2019. <span>“Prediction
of <span>Vrc01</span> Neutralization Sensitivity by <span>HIV</span>-1
Gp160 Sequence Features.”</span> <em>PLOS Computational Biology</em>. <a href="https://doi.org/10.1371/journal.pcbi.1006952">https://doi.org/10.1371/journal.pcbi.1006952</a>.
</div>
<div id="ref-williamson2020c" class="csl-entry">
Williamson, BD, and J Feng. 2020. <span>“Efficient Nonparametric
Statistical Inference on Population Feature Importance Using
<span>S</span>hapley Values.”</span> In <em>Proceedings of the 37th
International Conference on Machine Learning</em>, 119:10282–91.
Proceedings of Machine Learning Research. <a href="http://proceedings.mlr.press/v119/williamson20a.html">http://proceedings.mlr.press/v119/williamson20a.html</a>.
</div>
<div id="ref-williamson2020a" class="csl-entry">
Williamson, BD, PB Gilbert, M Carone, et al. 2020. <span>“Nonparametric
Variable Importance Assessment Using Machine Learning
Techniques.”</span> <em>Biometrics</em>.
</div>
<div id="ref-williamson2021" class="csl-entry">
Williamson, BD, PB Gilbert, NR Simon, et al. 2021. <span>“A General
Framework for Inference on Algorithm-Agnostic Variable
Importance.”</span> <em>Journal of the American Statistical
Association</em>. <a href="https://doi.org/10.1080/01621459.2021.2003200">https://doi.org/10.1080/01621459.2021.2003200</a>.
</div>
<div id="ref-zou2005" class="csl-entry">
Zou, H, and T Hastie. 2005. <span>“Regularization and Variable Selection
via the Elastic Net.”</span> <em>Journal of the Royal Statistical
Society: Series B (Statistical Methodology)</em> 67 (2): 301–20.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
